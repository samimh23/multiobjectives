{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1868a1be-4499-4bef-9d2c-cd06db353fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39d8b6f-2efc-413b-919e-a1ba1d50286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_profits_from_file(filename, num_objectives, num_items):\n",
    "    profits = np.zeros((num_objectives, num_items))\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    idx = 0\n",
    "    idx += 1  # skip header\n",
    "    for obj in range(num_objectives):\n",
    "        idx += 1  # skip capacity line\n",
    "        for item in range(num_items):\n",
    "            idx += 1  # skip \"n:\" line\n",
    "            idx += 1  # skip weight\n",
    "            profit = int(lines[idx])\n",
    "            profits[obj, item] = profit\n",
    "            idx += 1\n",
    "    return profits\n",
    "\n",
    "def load_weights_from_file(filename, num_objectives, num_items):\n",
    "    weights = np.zeros((num_objectives, num_items), dtype=int)\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    idx = 0\n",
    "    idx += 1  # skip header\n",
    "    for obj in range(num_objectives):\n",
    "        idx += 1  # skip capacity line\n",
    "        for item in range(num_items):\n",
    "            idx += 1  # skip \"n:\" line\n",
    "            weight = int(lines[idx])\n",
    "            weights[obj, item] = weight\n",
    "            idx += 2  # skip profit\n",
    "    return weights\n",
    "\n",
    "def load_capacities_from_file(filename, num_objectives, num_items):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    idx = 0\n",
    "    idx += 1  # skip header\n",
    "    capacities = []\n",
    "    for obj in range(num_objectives):\n",
    "        cap = float(lines[idx])\n",
    "        capacities.append(cap)\n",
    "        idx += 1 + 3 * num_items\n",
    "    return np.array(capacities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a65ff4e-1d40-4b8f-93d9-9fdb0508f992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM integration enabled - Ollama detected\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional LLM integration - falls back to built-in functions if not available\n",
    "ENABLE_LLM = False\n",
    "try:\n",
    "    import requests\n",
    "    OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "    MODEL_NAME = \"llama3\"\n",
    "    \n",
    "    # Test if Ollama is available\n",
    "    response = requests.get(\"http://localhost:11434/api/tags\", timeout=2)\n",
    "    if response.status_code == 200:\n",
    "        ENABLE_LLM = True\n",
    "        print(\"LLM integration enabled - Ollama detected\")\n",
    "    else:\n",
    "        print(\"LLM integration disabled - Ollama not available\")\n",
    "except:\n",
    "    print(\"LLM integration disabled - falling back to built-in functions\")\n",
    "\n",
    "# Mock LLM functions for when Ollama is not available\n",
    "def generate_llm_response(system_prompt, user_prompt, max_new_tokens=500):\n",
    "    \"\"\"Mock LLM response - returns basic function templates\"\"\"\n",
    "    if \"mutation\" in user_prompt.lower():\n",
    "        return \"\"\"\n",
    "def mutation_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    items_selected = np.where(observation == 1)[0]\n",
    "    items_unselected = np.where(observation == 0)[0]\n",
    "    if len(items_selected) == 0 or len(items_unselected) == 0:\n",
    "        return 0, 0\n",
    "    remove_idx = int(np.random.choice(items_selected))\n",
    "    add_idx = int(np.random.choice(items_unselected))\n",
    "    return remove_idx, add_idx\n",
    "\"\"\"\n",
    "    elif \"local_search\" in user_prompt.lower():\n",
    "        return \"\"\"\n",
    "def local_search_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    items_selected = np.where(observation == 1)[0]\n",
    "    items_unselected = np.where(observation == 0)[0]\n",
    "    if len(items_selected) == 0 or len(items_unselected) == 0 or profits is None:\n",
    "        return 0, 0\n",
    "    profs_selected = np.sum(profits[:, items_selected], axis=0)\n",
    "    profs_unselected = np.sum(profits[:, items_unselected], axis=0)\n",
    "    remove_idx = items_selected[np.argmin(profs_selected)]\n",
    "    add_idx = items_unselected[np.argmax(profs_unselected)]\n",
    "    return int(remove_idx), int(add_idx)\n",
    "\"\"\"\n",
    "    else:\n",
    "        return \"\"\"\n",
    "def default_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    items_selected = np.where(observation == 1)[0]\n",
    "    items_unselected = np.where(observation == 0)[0]\n",
    "    if len(items_selected) == 0 or len(items_unselected) == 0:\n",
    "        return 0, 0\n",
    "    remove_idx = int(np.random.choice(items_selected))\n",
    "    add_idx = int(np.random.choice(items_unselected))\n",
    "    return remove_idx, add_idx\n",
    "\"\"\"\n",
    "\n",
    "def extract_code_from_response(response):\n",
    "    \"\"\"Extract Python code from LLM response.\"\"\"\n",
    "    markers = [\n",
    "        (\"```python\", \"```\"),\n",
    "        (\"```Python\", \"```\"),\n",
    "        (\"```\", \"```\"),\n",
    "        (\"`\", \"`\")\n",
    "    ]\n",
    "    \n",
    "    for start_marker, end_marker in markers:\n",
    "        start_idx = response.find(start_marker)\n",
    "        if start_idx != -1:\n",
    "            start_idx += len(start_marker)\n",
    "            end_idx = response.find(end_marker, start_idx)\n",
    "            if end_idx != -1:\n",
    "                return response[start_idx:end_idx].strip()\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "def validate_function(code, function_name, input_args):\n",
    "    \"\"\"Validate if the generated function is syntactically correct and can be executed.\"\"\"\n",
    "    try:\n",
    "        namespace = {'np': np, 'numpy': np}\n",
    "        exec(code, namespace)\n",
    "        \n",
    "        if function_name not in namespace:\n",
    "            return False, f\"Function '{function_name}' not found in the generated code.\"\n",
    "        \n",
    "        func = namespace[function_name]\n",
    "        dummy_inputs = []\n",
    "        for arg in input_args:\n",
    "            if isinstance(arg, tuple) and arg[0] == 'array':\n",
    "                dummy_inputs.append(np.zeros(arg[1]))\n",
    "            elif isinstance(arg, tuple) and arg[0] == 'array_2d':\n",
    "                dummy_inputs.append(np.zeros(arg[1]))\n",
    "            elif isinstance(arg, tuple) and arg[0] == 'dict':\n",
    "                dummy_inputs.append({})\n",
    "            elif isinstance(arg, tuple) and arg[0] == 'float':\n",
    "                dummy_inputs.append(0.1)\n",
    "            else:\n",
    "                dummy_inputs.append(0)\n",
    "        \n",
    "        result = func(*dummy_inputs)\n",
    "        \n",
    "        if not isinstance(result, tuple) or len(result) != 2:\n",
    "            return False, f\"Function should return a tuple of two integers\"\n",
    "            \n",
    "        remove_idx, add_idx = result\n",
    "        if not isinstance(remove_idx, (int, np.integer)) or not isinstance(add_idx, (int, np.integer)):\n",
    "            return False, f\"Function should return integers\"\n",
    "        \n",
    "        return True, \"Function is valid.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Error validating function: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1a9c2d-d4f3-4f16-abc9-c211005b7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    items_selected = np.where(observation == 1)[0]\n",
    "    items_unselected = np.where(observation == 0)[0]\n",
    "    if len(items_selected) == 0 or len(items_unselected) == 0:\n",
    "        return 0, 0\n",
    "    remove_idx = int(np.random.choice(items_selected))\n",
    "    add_idx = int(np.random.choice(items_unselected))\n",
    "    return remove_idx, add_idx\n",
    "\n",
    "def local_search_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    items_selected = np.where(observation == 1)[0]\n",
    "    items_unselected = np.where(observation == 0)[0]\n",
    "    if len(items_selected) == 0 or len(items_unselected) == 0 or profits is None:\n",
    "        return 0, 0\n",
    "    profs_selected = np.sum(profits[:, items_selected], axis=0)\n",
    "    profs_unselected = np.sum(profits[:, items_unselected], axis=0)\n",
    "    remove_idx = items_selected[np.argmin(profs_selected)]\n",
    "    add_idx = items_unselected[np.argmax(profs_unselected)]\n",
    "    return int(remove_idx), int(add_idx)\n",
    "\n",
    "def global_search_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    items_selected = np.where(observation == 1)[0]\n",
    "    items_unselected = np.where(observation == 0)[0]\n",
    "    if len(items_selected) == 0 or len(items_unselected) == 0 or profits is None:\n",
    "        return 0, 0\n",
    "    profs_selected = np.sum(profits[:, items_selected], axis=0)\n",
    "    profs_unselected = np.sum(profits[:, items_unselected], axis=0)\n",
    "    ps = profs_selected + 1e-9\n",
    "    pu = profs_unselected + 1e-9\n",
    "    remove_idx = np.random.choice(items_selected, p=ps / np.sum(ps))\n",
    "    add_idx = np.random.choice(items_unselected, p=pu / np.sum(pu))\n",
    "    return int(remove_idx), int(add_idx)\n",
    "\n",
    "def follow_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    if best_observation is None:\n",
    "        return mutation_move(observation, profits, weights, capacities)\n",
    "    diff = best_observation - observation\n",
    "    add_candidates = np.where((diff == 1) & (observation == 0))[0]\n",
    "    remove_candidates = np.where((diff == -1) & (observation == 1))[0]\n",
    "    if len(add_candidates) == 0 or len(remove_candidates) == 0:\n",
    "        return mutation_move(observation, profits, weights, capacities)\n",
    "    add_idx = np.random.choice(add_candidates)\n",
    "    remove_idx = np.random.choice(remove_candidates)\n",
    "    return int(remove_idx), int(add_idx)\n",
    "\n",
    "def diversity_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    best_move = None\n",
    "    best_min_dist = -np.inf\n",
    "    items_selected = np.where(observation == 1)[0]\n",
    "    items_unselected = np.where(observation == 0)[0]\n",
    "    if len(items_selected) == 0 or len(items_unselected) == 0 or archive_objs is None:\n",
    "        return mutation_move(observation, profits, weights, capacities)\n",
    "    for _ in range(3):\n",
    "        remove_idx = int(np.random.choice(items_selected))\n",
    "        add_idx = int(np.random.choice(items_unselected))\n",
    "        candidate = observation.copy()\n",
    "        candidate[remove_idx] = 0\n",
    "        candidate[add_idx] = 1\n",
    "        candidate_objs = np.sum(profits * candidate, axis=1)\n",
    "        dists = np.linalg.norm(archive_objs - candidate_objs, axis=1)\n",
    "        min_dist = np.min(dists)\n",
    "        if min_dist > best_min_dist:\n",
    "            best_min_dist = min_dist\n",
    "            best_move = (remove_idx, add_idx)\n",
    "    return best_move if best_move is not None else (0, 0)\n",
    "\n",
    "# Registry for moves\n",
    "MOVE_REGISTRY = {\n",
    "    \"mutation\": mutation_move,\n",
    "    \"local_search\": local_search_move,\n",
    "    \"global_search\": global_search_move,\n",
    "    \"follow\": follow_move,\n",
    "    \"diversity\": diversity_move,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69791fe-326f-4396-a890-54d9ffbae4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMFunctionGenerator:\n",
    "    \"\"\"Class for generating and evolving heuristic functions using LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.function_cache = {}\n",
    "        self.generation_count = 0\n",
    "        self.max_generations = 5  # Reduced for performance\n",
    "        self.pre_generated_functions = {}\n",
    "        \n",
    "    def pre_generate_functions(self):\n",
    "        \"\"\"Pre-generate a diverse set of functions before optimization starts\"\"\"\n",
    "        move_types = [\"mutation\", \"local_search\", \"global_search\", \"follow\", \"diversity\"]\n",
    "        for move_type in move_types:\n",
    "            for i in range(2):  # Generate 2 variants per move type\n",
    "                code = self.generate_sub_function(move_type)\n",
    "                if code:\n",
    "                    self.pre_generated_functions[f\"{move_type}_{i}\"] = code\n",
    "        print(f\"Pre-generated {len(self.pre_generated_functions)} functions\")\n",
    "    \n",
    "    def generate_sub_function(self, function_type, context=None):\n",
    "        \"\"\"Generate a new sub-function using LLM.\"\"\"\n",
    "        if self.generation_count >= self.max_generations:\n",
    "            return MOVE_REGISTRY.get(function_type, mutation_move)\n",
    "        \n",
    "        cache_key = f\"sub_function_{function_type}_{self.generation_count}\"\n",
    "        if cache_key in self.function_cache:\n",
    "            return self.function_cache[cache_key]\n",
    "        \n",
    "        try:\n",
    "            user_prompt = f\"Design a Python function for {function_type} move in a multi-objective knapsack problem.\"\n",
    "            response = generate_llm_response(\"You are an expert in optimization heuristics.\", user_prompt)\n",
    "            code = extract_code_from_response(response)\n",
    "            self.generation_count += 1\n",
    "            \n",
    "            # Validate the function\n",
    "            input_args = [('array', 250), ('array_2d', (2, 250)), ('array_2d', (2, 250)), ('array', 2), None, None]\n",
    "            is_valid, message = validate_function(code, f\"{function_type}_move\", input_args)\n",
    "            \n",
    "            if not is_valid:\n",
    "                print(f\"Generated function is invalid: {message}\")\n",
    "                return MOVE_REGISTRY.get(function_type, mutation_move)\n",
    "            \n",
    "            # Store in cache\n",
    "            self.function_cache[cache_key] = code\n",
    "            return code\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating function: {e}\")\n",
    "            return MOVE_REGISTRY.get(function_type, mutation_move)\n",
    "    \n",
    "    def crossover_evolution(self, parent1_code, parent2_code, function_type):\n",
    "        \"\"\"Perform crossover evolution between two parent functions.\"\"\"\n",
    "        return parent1_code  # Simplified for now\n",
    "    \n",
    "    def cooperative_evolution(self, sub_function_code, arch_function_code):\n",
    "        \"\"\"Perform cooperative evolution between functions.\"\"\"\n",
    "        return sub_function_code, arch_function_code  # Simplified for now\n",
    "    \n",
    "    def architecture_upgrade(self, arch_function_code, performance_feedback):\n",
    "        \"\"\"Upgrade the architecture function based on performance feedback.\"\"\"\n",
    "        return arch_function_code  # Simplified for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8475462-b4c2-428a-9f5a-e4e65797dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAgentArchitecture:\n",
    "    \"\"\"Enhanced architecture function with LLM integration for evolution.\"\"\"\n",
    "    \n",
    "    def __init__(self, move_types, smoothing=0.1, llm_generator=None):\n",
    "        self.move_types = list(move_types)\n",
    "        self.move_counts = {k: 1 for k in self.move_types}\n",
    "        self.move_successes = {k: 1 for k in self.move_types}\n",
    "        self.move_probs = np.ones(len(self.move_types)) / len(self.move_types)\n",
    "        self.smoothing = smoothing\n",
    "        self.llm_generator = llm_generator\n",
    "        self.performance_history = []\n",
    "        self.upgrade_count = 0\n",
    "        \n",
    "    def select_move(self):\n",
    "        if len(self.move_types) == 0:\n",
    "            return \"mutation\"\n",
    "        idx = np.random.choice(len(self.move_types), p=self.move_probs)\n",
    "        return self.move_types[idx]\n",
    "    \n",
    "    def report_move_result(self, move_type, success):\n",
    "        if move_type not in self.move_types:\n",
    "            return\n",
    "        if move_type not in self.move_counts:\n",
    "            self.move_counts[move_type] = 1\n",
    "        if move_type not in self.move_successes:\n",
    "            self.move_successes[move_type] = 1\n",
    "            \n",
    "        self.move_counts[move_type] += 1\n",
    "        if success:\n",
    "            self.move_successes[move_type] += 1\n",
    "        \n",
    "        # Update probabilities\n",
    "        rates = np.array([self.move_successes[k]/self.move_counts[k] for k in self.move_types], dtype=np.float64)\n",
    "        rates = np.clip(rates, 1e-8, 1.0)  # Prevent numerical issues\n",
    "        exp_rates = np.exp(rates / self.smoothing)\n",
    "        new_probs = exp_rates / np.sum(exp_rates)\n",
    "        self.move_probs = 0.5 * self.move_probs + 0.5 * new_probs\n",
    "        self.move_probs = self.move_probs / np.sum(self.move_probs)\n",
    "        \n",
    "        self.performance_history.append({\n",
    "            'move_type': move_type,\n",
    "            'success': success,\n",
    "            'rates': rates.copy(),\n",
    "            'probs': self.move_probs.copy()\n",
    "        })\n",
    "    \n",
    "    def clone(self):\n",
    "        arch = EnhancedAgentArchitecture(self.move_types, self.smoothing, self.llm_generator)\n",
    "        arch.move_counts = dict(self.move_counts)\n",
    "        arch.move_successes = dict(self.move_successes)\n",
    "        arch.move_probs = np.copy(self.move_probs)\n",
    "        arch.performance_history = list(self.performance_history)\n",
    "        return arch\n",
    "    \n",
    "    def mutate(self, registry, mutation_rate=0.25):\n",
    "        move_types = set(self.move_types)\n",
    "        all_types = set(registry.keys())\n",
    "        \n",
    "        # Add new move type\n",
    "        if random.random() < mutation_rate and len(move_types) < len(all_types):\n",
    "            available_types = all_types - move_types\n",
    "            if available_types:\n",
    "                add = random.choice(list(available_types))\n",
    "                move_types.add(add)\n",
    "        \n",
    "        # Remove poor performing move type\n",
    "        if random.random() < mutation_rate and len(move_types) > 2:\n",
    "            # Only consider move types that exist in our counts\n",
    "            valid_move_types = [k for k in move_types if k in self.move_counts and k in self.move_successes]\n",
    "            if len(valid_move_types) > 2:\n",
    "                success_rates = {k: self.move_successes[k]/max(self.move_counts[k], 1) for k in valid_move_types}\n",
    "                worst_move = min(success_rates, key=success_rates.get)\n",
    "                if success_rates[worst_move] < 0.2:  # Only remove if really poor\n",
    "                    move_types.remove(worst_move)\n",
    "        \n",
    "        self.move_types = list(move_types)\n",
    "        random.shuffle(self.move_types)\n",
    "        \n",
    "        # Ensure all move types have entries in counts and successes\n",
    "        for move_type in self.move_types:\n",
    "            if move_type not in self.move_counts:\n",
    "                self.move_counts[move_type] = 1\n",
    "            if move_type not in self.move_successes:\n",
    "                self.move_successes[move_type] = 1\n",
    "        \n",
    "        # Remove entries for move types no longer in use\n",
    "        old_counts = dict(self.move_counts)\n",
    "        old_successes = dict(self.move_successes)\n",
    "        self.move_counts = {k: old_counts.get(k, 1) for k in self.move_types}\n",
    "        self.move_successes = {k: old_successes.get(k, 1) for k in self.move_types}\n",
    "        \n",
    "        # Recalculate probabilities\n",
    "        if len(self.move_types) > 0:\n",
    "            self.move_probs = np.ones(len(self.move_types)) / len(self.move_types)\n",
    "        else:\n",
    "            self.move_types = [\"mutation\"]\n",
    "            self.move_counts = {\"mutation\": 1}\n",
    "            self.move_successes = {\"mutation\": 1}\n",
    "            self.move_probs = np.array([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b733bb9-59e4-455d-8d25-1efad2790a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedModularMetaAgent:\n",
    "    \"\"\"Enhanced modular agent with improved adaptation and optional LLM integration.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_items, num_objectives, profits, weights, capacities, \n",
    "                 move_types=None, smoothing=0.1, llm_generator=None):\n",
    "        self.num_items = num_items\n",
    "        self.num_objectives = num_objectives\n",
    "        self.profits = profits\n",
    "        self.weights = weights\n",
    "        self.capacities = capacities\n",
    "        self.llm_generator = llm_generator\n",
    "        self.custom_moves = {}\n",
    "        self.evolution_count = 0\n",
    "        self.max_evolution_count = 3  # Limit LLM calls\n",
    "        \n",
    "        self.architecture = EnhancedAgentArchitecture(\n",
    "            move_types if move_types else list(MOVE_REGISTRY.keys()), \n",
    "            smoothing=smoothing,\n",
    "            llm_generator=llm_generator\n",
    "        )\n",
    "        \n",
    "        self.best_observation = None\n",
    "        self.last_move_type = None\n",
    "        self.performance_history = []\n",
    "        self.fitness_history = []\n",
    "    \n",
    "    def observe(self, state):\n",
    "        return np.array(state[\"Items\"], dtype=np.int32)\n",
    "    \n",
    "    def act(self, observation, context=None):\n",
    "        archive_objs = context.get(\"archive_objs\") if context else None\n",
    "        best_obs = self.best_observation\n",
    "        \n",
    "        # Try to get a feasible move\n",
    "        for attempt in range(3):\n",
    "            move_type = self.architecture.select_move()\n",
    "            \n",
    "            # Select move function\n",
    "            if move_type in self.custom_moves:\n",
    "                move_fn = self.custom_moves[move_type]\n",
    "            elif move_type in MOVE_REGISTRY:\n",
    "                move_fn = MOVE_REGISTRY[move_type]\n",
    "            else:\n",
    "                # Fallback to mutation if unknown move type\n",
    "                move_fn = MOVE_REGISTRY[\"mutation\"]\n",
    "                move_type = \"mutation\"\n",
    "            \n",
    "            try:\n",
    "                move = move_fn(\n",
    "                    observation, self.profits, self.weights, self.capacities,\n",
    "                    archive_objs=archive_objs, best_observation=best_obs\n",
    "                )\n",
    "                \n",
    "                if self._is_feasible(observation, move):\n",
    "                    self.last_move_type = move_type\n",
    "                    return move\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error executing move {move_type}: {str(e)}\")\n",
    "        \n",
    "        # Final fallback\n",
    "        move = mutation_move(observation, self.profits, self.weights, self.capacities)\n",
    "        self.last_move_type = \"mutation\"\n",
    "        return move\n",
    "    \n",
    "    def report_move_result(self, move_type, success, fitness=None):\n",
    "        if move_type is None:\n",
    "            move_type = self.last_move_type\n",
    "            \n",
    "        self.architecture.report_move_result(move_type, success)\n",
    "        \n",
    "        self.performance_history.append({\n",
    "            'move_type': move_type,\n",
    "            'success': success,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "        \n",
    "        if fitness is not None:\n",
    "            self.fitness_history.append(fitness)\n",
    "            # Keep only recent history for memory efficiency\n",
    "            if len(self.fitness_history) > 100:\n",
    "                self.fitness_history = self.fitness_history[-50:]\n",
    "    \n",
    "    def update_best(self, observation):\n",
    "        self.best_observation = observation.copy()\n",
    "    \n",
    "    def _is_feasible(self, observation, move):\n",
    "        if self.weights is None or self.capacities is None or move is None:\n",
    "            return True\n",
    "        \n",
    "        try:\n",
    "            remove_idx, add_idx = move\n",
    "            \n",
    "            # Basic checks\n",
    "            if (remove_idx == add_idx or \n",
    "                remove_idx < 0 or remove_idx >= self.num_items or\n",
    "                add_idx < 0 or add_idx >= self.num_items):\n",
    "                return False\n",
    "            \n",
    "            # Check current state\n",
    "            if observation[remove_idx] == 0 or observation[add_idx] == 1:\n",
    "                return False\n",
    "            \n",
    "            # Check capacity constraints\n",
    "            items = observation.copy()\n",
    "            items[remove_idx] = 0\n",
    "            items[add_idx] = 1\n",
    "            \n",
    "            total_weights = np.sum(self.weights * items, axis=1)\n",
    "            return np.all(total_weights <= self.capacities)\n",
    "            \n",
    "        except (ValueError, IndexError, TypeError):\n",
    "            return False\n",
    "    \n",
    "    def clone(self):\n",
    "        agent = EnhancedModularMetaAgent(\n",
    "            self.num_items, self.num_objectives, self.profits, self.weights, self.capacities,\n",
    "            move_types=self.architecture.move_types,\n",
    "            smoothing=self.architecture.smoothing,\n",
    "            llm_generator=self.llm_generator\n",
    "        )\n",
    "        \n",
    "        agent.architecture = self.architecture.clone()\n",
    "        agent.custom_moves = dict(self.custom_moves)\n",
    "        agent.evolution_count = self.evolution_count\n",
    "        agent.max_evolution_count = self.max_evolution_count\n",
    "        \n",
    "        if self.best_observation is not None:\n",
    "            agent.best_observation = self.best_observation.copy()\n",
    "        \n",
    "        # Copy recent performance history\n",
    "        agent.performance_history = list(self.performance_history[-20:])\n",
    "        agent.fitness_history = list(self.fitness_history[-20:])\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def mutate(self, registry, mutation_rate=0.25):\n",
    "        self.architecture.mutate(registry, mutation_rate=mutation_rate)\n",
    "        \n",
    "        # Occasionally try to generate new custom moves (if LLM available)\n",
    "        if (ENABLE_LLM and self.llm_generator and \n",
    "            random.random() < 0.1 and \n",
    "            self.evolution_count < self.max_evolution_count):\n",
    "            \n",
    "            move_type = random.choice(self.architecture.move_types)\n",
    "            try:\n",
    "                code = self.llm_generator.generate_sub_function(move_type)\n",
    "                if code:\n",
    "                    namespace = {'np': np, 'random': random}\n",
    "                    exec(code, namespace)\n",
    "                    self.custom_moves[move_type] = namespace[f\"{move_type}_move\"]\n",
    "                    self.evolution_count += 1\n",
    "                    print(f\"Generated new {move_type} move for agent\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to generate new move function: {str(e)}\")\n",
    "    \n",
    "    def get_performance_stats(self):\n",
    "        \"\"\"Get performance statistics for this agent\"\"\"\n",
    "        if not self.performance_history:\n",
    "            return {\"success_rate\": 0.0, \"move_diversity\": 0, \"avg_fitness\": 0.0}\n",
    "        \n",
    "        recent_history = self.performance_history[-50:]  # Last 50 moves\n",
    "        success_rate = sum(1 for h in recent_history if h['success']) / len(recent_history)\n",
    "        move_types = set(h['move_type'] for h in recent_history)\n",
    "        move_diversity = len(move_types)\n",
    "        avg_fitness = np.mean(self.fitness_history[-20:]) if self.fitness_history else 0.0\n",
    "        \n",
    "        return {\n",
    "            \"success_rate\": success_rate,\n",
    "            \"move_diversity\": move_diversity,\n",
    "            \"avg_fitness\": avg_fitness,\n",
    "            \"total_moves\": len(self.performance_history),\n",
    "            \"evolution_count\": self.evolution_count\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e990ec1c-c30b-4675-ba9c-9f76d54b9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAgentPopulationManager:\n",
    "    \"\"\"Enhanced population manager with LLM-based GSES cycle.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_agents, num_items, num_objectives, profits, weights, capacities, llm_generator=None):\n",
    "        self.num_agents = num_agents\n",
    "        self.llm_generator = llm_generator\n",
    "        self.registry = MOVE_REGISTRY\n",
    "        self.evolution_count = 0\n",
    "        \n",
    "        self.agents = [\n",
    "            EnhancedModularMetaAgent(\n",
    "                num_items, num_objectives, profits, weights, capacities,\n",
    "                move_types=random.sample(list(MOVE_REGISTRY.keys()), k=random.randint(2, len(MOVE_REGISTRY))),\n",
    "                llm_generator=llm_generator\n",
    "            )\n",
    "            for _ in range(num_agents)\n",
    "        ]\n",
    "        \n",
    "        self.agent_stats = [{\"fitness_sum\": 0.0, \"moves\": 0} for _ in range(num_agents)]\n",
    "        self.generation = 0\n",
    "        self.performance_history = []\n",
    "    \n",
    "    def select_agent_for_solution(self, solution_idx):\n",
    "        return self.agents[solution_idx % self.num_agents]\n",
    "    \n",
    "    def report_agent_performance(self, agent_idx, solution_fitness):\n",
    "        if 0 <= agent_idx < len(self.agent_stats):\n",
    "            self.agent_stats[agent_idx][\"fitness_sum\"] += solution_fitness\n",
    "            self.agent_stats[agent_idx][\"moves\"] += 1\n",
    "    \n",
    "    def gses_agent_level(self):\n",
    "        \"\"\"Perform the GSES cycle at the agent level.\"\"\"\n",
    "        avg_fitness = []\n",
    "        for s in self.agent_stats:\n",
    "            if s[\"moves\"] > 0:\n",
    "                avg_fitness.append(s[\"fitness_sum\"] / s[\"moves\"])\n",
    "            else:\n",
    "                avg_fitness.append(-1e9)\n",
    "        \n",
    "        sorted_idx = np.argsort(-np.array(avg_fitness))\n",
    "        survivors = [self.agents[i] for i in sorted_idx[:max(2, self.num_agents//2)]]\n",
    "        \n",
    "        self.performance_history.append({\n",
    "            'generation': self.generation,\n",
    "            'best_fitness': max(avg_fitness),\n",
    "            'avg_fitness': np.mean(avg_fitness),\n",
    "            'num_survivors': len(survivors)\n",
    "        })\n",
    "        \n",
    "        new_agents = []\n",
    "        while len(new_agents) + len(survivors) < self.num_agents:\n",
    "            if random.random() < 0.7 and len(survivors) >= 2:\n",
    "                # Crossover\n",
    "                parent1, parent2 = random.sample(survivors, 2)\n",
    "                child = parent1.clone()\n",
    "                \n",
    "                # Simple crossover: combine move types\n",
    "                moves1 = set(parent1.architecture.move_types)\n",
    "                moves2 = set(parent2.architecture.move_types)\n",
    "                moves_child = list(moves1 | moves2)\n",
    "                \n",
    "                if len(moves_child) > 2:\n",
    "                    moves_child = random.sample(moves_child, k=random.randint(2, len(moves_child)))\n",
    "                \n",
    "                child.architecture.move_types = moves_child\n",
    "                child.architecture.move_counts = {k: 1 for k in moves_child}\n",
    "                child.architecture.move_successes = {k: 1 for k in moves_child}\n",
    "                child.architecture.move_probs = np.ones(len(moves_child)) / len(moves_child)\n",
    "                \n",
    "                child.mutate(self.registry, mutation_rate=0.25)\n",
    "                new_agents.append(child)\n",
    "            else:\n",
    "                # Mutation only\n",
    "                parent = random.choice(survivors)\n",
    "                child = parent.clone()\n",
    "                child.mutate(self.registry, mutation_rate=0.5)\n",
    "                new_agents.append(child)\n",
    "        \n",
    "        self.agents = survivors + new_agents\n",
    "        self.agent_stats = [{\"fitness_sum\": 0.0, \"moves\": 0} for _ in range(self.num_agents)]\n",
    "        self.generation += 1\n",
    "        \n",
    "        if avg_fitness:\n",
    "            print(f\"Generation {self.generation}: Best fitness = {max(avg_fitness):.2f}, Avg fitness = {np.mean(avg_fitness):.2f}\")\n",
    "    \n",
    "    def evolve_with_llm(self):\n",
    "        \"\"\"Perform LLM-based evolution on the population.\"\"\"\n",
    "        # Simplified for now - just call regular GSES\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e3226bd-cae0-4458-af34-5458eccfc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.stdlib cimport malloc, free, srand, rand\n",
    "from libc.string cimport memset\n",
    "from libc.math cimport exp\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import time\n",
    "\n",
    "cdef struct ind:\n",
    "    int nombr_nonpris\n",
    "    int nombr\n",
    "    int rank\n",
    "    float fitnessbest\n",
    "    float fitness\n",
    "    int explored\n",
    "    double *f\n",
    "    double *capa\n",
    "    double *v\n",
    "    int *d\n",
    "    int *Items\n",
    "\n",
    "cdef struct pop:\n",
    "    int size\n",
    "    int maxsize\n",
    "    ind **ind_array\n",
    "\n",
    "cdef int NBITEMS = 250\n",
    "cdef int ni = 250\n",
    "cdef int L = 5\n",
    "cdef double LARGE = 10e50\n",
    "cdef float smallValue = 0.0000001\n",
    "cdef double kappa = 0.05\n",
    "cdef int alpha = 10\n",
    "cdef int paretoIni = 28000\n",
    "cdef int nf = 2\n",
    "cdef double *capacities = NULL\n",
    "cdef int **weights = NULL\n",
    "cdef int **profits = NULL\n",
    "cdef double *vector_weight = NULL\n",
    "cdef double max_bound = 0.0\n",
    "cdef double **OBJ_Weights = NULL\n",
    "cdef int nombreLIGNE = 0\n",
    "cdef int nextLn = 0\n",
    "cdef int inv = 0\n",
    "cdef int OBJ_Weights_lines = 0\n",
    "\n",
    "cdef public object py_agent_manager = None\n",
    "cdef public object move_stats = None\n",
    "\n",
    "def set_agent_manager(agent_manager):\n",
    "    global py_agent_manager\n",
    "    py_agent_manager = agent_manager\n",
    "\n",
    "def reset_move_stats():\n",
    "    global move_stats\n",
    "    move_stats = {\"total_agent_calls\": 0, \"move_type_counts\": {}, \"total_time_agent\": 0.0, \"total_time_loop\": 0.0}\n",
    "\n",
    "def print_move_stats():\n",
    "    print(\"\\n=== AGENT MOVE PROFILE ===\")\n",
    "    print(\"Total agent calls:\", move_stats[\"total_agent_calls\"])\n",
    "    print(\"Move type counts:\", move_stats[\"move_type_counts\"])\n",
    "    print(\"Total agent time (sec):\", move_stats[\"total_time_agent\"])\n",
    "    print(\"Total loop time (sec):\", move_stats[\"total_time_loop\"])\n",
    "    if move_stats[\"total_agent_calls\"] > 0:\n",
    "        print(\"Avg agent call time (ms):\", 1000.0 * move_stats[\"total_time_agent\"] / move_stats[\"total_agent_calls\"])\n",
    "\n",
    "def seed(int x):\n",
    "    srand(x)\n",
    "\n",
    "cdef int irand(int range_val):\n",
    "    return rand() % range_val\n",
    "\n",
    "cdef void *chk_malloc(size_t size):\n",
    "    cdef void *return_value = malloc(size)\n",
    "    if return_value == NULL:\n",
    "        raise MemoryError(\"Out of memory.\")\n",
    "    memset(return_value, 0, size)\n",
    "    return return_value\n",
    "\n",
    "cdef pop *create_pop(int maxsize, int nf):\n",
    "    cdef int i\n",
    "    cdef pop *pp = <pop *>chk_malloc(sizeof(pop))\n",
    "    pp.size = 0\n",
    "    pp.maxsize = maxsize\n",
    "    pp.ind_array = <ind **>chk_malloc(maxsize * sizeof(void*))\n",
    "    for i in range(maxsize):\n",
    "        pp.ind_array[i] = NULL\n",
    "    return pp\n",
    "\n",
    "cdef ind *create_ind(int nf):\n",
    "    cdef int i\n",
    "    cdef ind *p_ind = <ind *>chk_malloc(sizeof(ind))\n",
    "    p_ind.nombr_nonpris = 0\n",
    "    p_ind.nombr = 0\n",
    "    p_ind.rank = 0\n",
    "    p_ind.fitnessbest = -1.0\n",
    "    p_ind.fitness = -1.0\n",
    "    p_ind.explored = 0\n",
    "    p_ind.f = <double *>chk_malloc(nf * sizeof(double))\n",
    "    p_ind.capa = <double *>chk_malloc(nf * sizeof(double))\n",
    "    p_ind.v = <double *>chk_malloc(nf * sizeof(double))\n",
    "    p_ind.d = <int *>chk_malloc(ni * sizeof(int))\n",
    "    p_ind.Items = <int *>chk_malloc(ni * sizeof(int))\n",
    "    for i in range(ni):\n",
    "        p_ind.Items[i] = 0\n",
    "        p_ind.d[i] = 0\n",
    "    for i in range(nf):\n",
    "        p_ind.f[i] = 0.0\n",
    "        p_ind.capa[i] = 0.0\n",
    "        p_ind.v[i] = 0.0\n",
    "    return p_ind\n",
    "\n",
    "cdef ind *ind_copy(ind *i):\n",
    "    cdef ind *p_ind = create_ind(nf)\n",
    "    cdef int k\n",
    "    p_ind.nombr_nonpris = i.nombr_nonpris\n",
    "    p_ind.nombr = i.nombr\n",
    "    p_ind.rank = i.rank\n",
    "    p_ind.fitnessbest = i.fitnessbest\n",
    "    p_ind.fitness = i.fitness\n",
    "    p_ind.explored = i.explored\n",
    "    for k in range(nf):\n",
    "        p_ind.f[k] = i.f[k]\n",
    "        p_ind.v[k] = i.v[k]\n",
    "        p_ind.capa[k] = i.capa[k]\n",
    "    for k in range(ni):\n",
    "        p_ind.d[k] = i.d[k]\n",
    "        p_ind.Items[k] = i.Items[k]\n",
    "    return p_ind\n",
    "\n",
    "cdef void free_ind(ind *p_ind):\n",
    "    if p_ind != NULL:\n",
    "        free(p_ind.d)\n",
    "        free(p_ind.f)\n",
    "        free(p_ind.capa)\n",
    "        free(p_ind.v)\n",
    "        free(p_ind.Items)\n",
    "        free(p_ind)\n",
    "\n",
    "cdef void complete_free_pop(pop *pp):\n",
    "    cdef int i\n",
    "    if pp != NULL:\n",
    "        if pp.ind_array != NULL:\n",
    "            for i in range(pp.size):\n",
    "                if pp.ind_array[i] != NULL:\n",
    "                    free_ind(pp.ind_array[i])\n",
    "                    pp.ind_array[i] = NULL\n",
    "            free(pp.ind_array)\n",
    "        free(pp)\n",
    "\n",
    "cdef void cleanup_globals():\n",
    "    global capacities, weights, profits, vector_weight, OBJ_Weights, OBJ_Weights_lines, nf, ni\n",
    "    if capacities != NULL:\n",
    "        free(capacities)\n",
    "        capacities = NULL\n",
    "    if weights != NULL:\n",
    "        for i in range(nf):\n",
    "            if weights[i] != NULL:\n",
    "                free(weights[i])\n",
    "        free(weights)\n",
    "        weights = NULL\n",
    "    if profits != NULL:\n",
    "        for i in range(nf):\n",
    "            if profits[i] != NULL:\n",
    "                free(profits[i])\n",
    "        free(profits)\n",
    "        profits = NULL\n",
    "    if vector_weight != NULL:\n",
    "        free(vector_weight)\n",
    "        vector_weight = NULL\n",
    "    if OBJ_Weights != NULL:\n",
    "        for i in range(nf):\n",
    "            if OBJ_Weights[i] != NULL:\n",
    "                free(OBJ_Weights[i])\n",
    "        free(OBJ_Weights)\n",
    "        OBJ_Weights = NULL\n",
    "    OBJ_Weights_lines = 0\n",
    "    nf = 0\n",
    "    ni = 0\n",
    "\n",
    "cdef int non_dominated(ind *p_ind_a, ind *p_ind_b):\n",
    "    cdef int i\n",
    "    cdef int a_is_good = -1\n",
    "    cdef int equal = 1\n",
    "    for i in range(nf):\n",
    "        if p_ind_a.f[i] > p_ind_b.f[i]:\n",
    "            a_is_good = 1\n",
    "        if p_ind_a.f[i] != p_ind_b.f[i]:\n",
    "            equal = 0\n",
    "    if equal:\n",
    "        return 0\n",
    "    return a_is_good\n",
    "\n",
    "cdef double calcAddEpsIndicator(ind *p_ind_a, ind *p_ind_b):\n",
    "    global max_bound\n",
    "    cdef int i\n",
    "    cdef double eps\n",
    "    cdef double temp_eps\n",
    "    if max_bound == 0.0:\n",
    "        max_bound = 1e-8\n",
    "    eps = (p_ind_a.v[0]/max_bound)-(p_ind_b.v[0]/max_bound)\n",
    "    for i in range(1, nf):\n",
    "        temp_eps = (p_ind_a.v[i]/max_bound)-(p_ind_b.v[i]/max_bound)\n",
    "        if temp_eps > eps:\n",
    "            eps = temp_eps\n",
    "    return eps\n",
    "\n",
    "cdef void init_fitness(ind *x):\n",
    "    x.fitness = 0.0\n",
    "\n",
    "cdef void update_fitness(ind *x, double I):\n",
    "    x.fitness -= exp(-I / kappa)\n",
    "\n",
    "cdef double update_fitness_return(double f, double I):\n",
    "    return f - exp(-I / kappa)\n",
    "\n",
    "cdef int delete_fitness(ind *x, double I):\n",
    "    x.fitness += exp(-I / kappa)\n",
    "    return 0\n",
    "\n",
    "cdef void compute_ind_fitness(ind *x, pop *SP):\n",
    "    cdef int j\n",
    "    init_fitness(x)\n",
    "    for j in range(SP.size):\n",
    "        if SP.ind_array[j] != x:\n",
    "            update_fitness(x, calcAddEpsIndicator(SP.ind_array[j], x))\n",
    "\n",
    "cdef void compute_all_fitness(pop *SP):\n",
    "    cdef int i\n",
    "    for i in range(SP.size):\n",
    "        compute_ind_fitness(SP.ind_array[i], SP)\n",
    "\n",
    "cdef void loadMOKP(char *filename):\n",
    "    global nf, ni, capacities, weights, profits\n",
    "    cdef int i, f\n",
    "    with open(filename.decode(), \"r\") as source:\n",
    "        _nf, _ni = [int(x) for x in source.readline().split()]\n",
    "        nf = _nf\n",
    "        ni = _ni\n",
    "        capacities = <double *>chk_malloc(nf * sizeof(double))\n",
    "        weights = <int **>chk_malloc(nf * sizeof(void*))\n",
    "        profits = <int **>chk_malloc(nf * sizeof(void*))\n",
    "        for f in range(nf):\n",
    "            capacities[f] = float(source.readline().strip())\n",
    "            weights[f] = <int *>chk_malloc(ni * sizeof(int))\n",
    "            profits[f] = <int *>chk_malloc(ni * sizeof(int))\n",
    "            for i in range(ni):\n",
    "                source.readline()\n",
    "                weights[f][i] = int(source.readline().strip())\n",
    "                profits[f][i] = int(source.readline().strip())\n",
    "\n",
    "cdef void read_weights_file(char *filename):\n",
    "    global OBJ_Weights, nombreLIGNE, nf, OBJ_Weights_lines\n",
    "    cdef int i, j, nlines\n",
    "    with open(filename.decode(), \"r\") as f:\n",
    "        lines = [line for line in f if line.strip()]\n",
    "    nlines = len(lines)\n",
    "    OBJ_Weights = <double **>chk_malloc(nf * sizeof(void*))\n",
    "    for i in range(nf):\n",
    "        OBJ_Weights[i] = <double *>chk_malloc(nlines * sizeof(double))\n",
    "    for i, line in enumerate(lines):\n",
    "        vals = line.strip().split()\n",
    "        for j in range(nf):\n",
    "            OBJ_Weights[j][i] = float(vals[j])\n",
    "    nombreLIGNE = nlines - 1\n",
    "    OBJ_Weights_lines = nlines\n",
    "\n",
    "cdef void dynamic_weight_allpop():\n",
    "    global vector_weight, OBJ_Weights, nombreLIGNE, nf, nextLn\n",
    "    cdef int i\n",
    "    if vector_weight == NULL:\n",
    "        vector_weight = <double *>chk_malloc(nf * sizeof(double))\n",
    "    for i in range(nf):\n",
    "        vector_weight[i] = OBJ_Weights[i][nextLn]\n",
    "    if nextLn == nombreLIGNE:\n",
    "        nextLn = 0\n",
    "    else:\n",
    "        nextLn += 1\n",
    "\n",
    "cdef void choose_weight():\n",
    "    dynamic_weight_allpop()\n",
    "\n",
    "cdef void random_init_ind(ind *x):\n",
    "    cdef int j, r, tmp\n",
    "    for j in range(ni):\n",
    "        x.d[j] = j\n",
    "    for j in range(ni):\n",
    "        r = irand(ni)\n",
    "        tmp = x.d[r]\n",
    "        x.d[r] = x.d[j]\n",
    "        x.d[j] = tmp\n",
    "\n",
    "cdef void evaluate(ind *x):\n",
    "    cdef int j, l, k, faisable\n",
    "    x.nombr = 0\n",
    "    x.nombr_nonpris = 0\n",
    "    for j in range(nf):\n",
    "        x.capa[j] = 0.0\n",
    "        x.f[j] = 0.0\n",
    "    for j in range(ni):\n",
    "        l = 0\n",
    "        faisable = 1\n",
    "        while l < nf and faisable == 1:\n",
    "            if x.capa[l] + weights[l][x.d[j]] > capacities[l]:\n",
    "                faisable = 0\n",
    "            l += 1\n",
    "        if faisable == 1:\n",
    "            for k in range(nf):\n",
    "                x.capa[k] += weights[k][x.d[j]]\n",
    "                x.f[k] += profits[k][x.d[j]]\n",
    "            x.Items[x.d[j]] = 1\n",
    "            x.nombr += 1\n",
    "        else:\n",
    "            x.Items[x.d[j]] = 0\n",
    "            x.nombr_nonpris += 1\n",
    "\n",
    "cdef void P_init_pop(pop *SP, pop *Sarchive, int alpha):\n",
    "    cdef int i, x, tmp, t\n",
    "    t = max(alpha, Sarchive.size)\n",
    "    cdef int* shuffle = <int *>chk_malloc(t * sizeof(int))\n",
    "    for i in range(t):\n",
    "        shuffle[i] = i\n",
    "    for i in range(t):\n",
    "        x = irand(alpha)\n",
    "        tmp = shuffle[i]\n",
    "        shuffle[i] = shuffle[x]\n",
    "        shuffle[x] = tmp\n",
    "    SP.size = alpha\n",
    "    if Sarchive.size > alpha:\n",
    "        for i in range(alpha):\n",
    "            SP.ind_array[i] = ind_copy(Sarchive.ind_array[shuffle[i]])\n",
    "    else:\n",
    "        for i in range(alpha):\n",
    "            if shuffle[i] < Sarchive.size:\n",
    "                SP.ind_array[i] = ind_copy(Sarchive.ind_array[shuffle[i]])\n",
    "            else:\n",
    "                SP.ind_array[i] = create_ind(nf)\n",
    "                random_init_ind(SP.ind_array[i])\n",
    "                evaluate(SP.ind_array[i])\n",
    "    free(shuffle)\n",
    "\n",
    "cdef int extractPtoArchive(pop *P, pop *archive):\n",
    "    cdef int i, j, dom, t, convergence_rate\n",
    "    t = archive.size + P.size\n",
    "    archiveAndP = create_pop(t, nf)\n",
    "    convergence_rate = 0\n",
    "    for i in range(archive.size):\n",
    "        archiveAndP.ind_array[i] = archive.ind_array[i]\n",
    "    for i in range(P.size):\n",
    "        archiveAndP.ind_array[i + archive.size] = ind_copy(P.ind_array[i])\n",
    "    archiveAndP.size = t\n",
    "    archive.size = 0\n",
    "    for i in range(t):\n",
    "        for j in range(t):\n",
    "            if i != j:\n",
    "                dom = non_dominated(archiveAndP.ind_array[i], archiveAndP.ind_array[j])\n",
    "                if dom == -1 or (dom == 0 and i > j):\n",
    "                    break\n",
    "        else:\n",
    "            archive.ind_array[archive.size] = ind_copy(archiveAndP.ind_array[i])\n",
    "            archive.size += 1\n",
    "            if i >= t - P.size:\n",
    "                convergence_rate += 1\n",
    "    complete_free_pop(archiveAndP)\n",
    "    return convergence_rate\n",
    "\n",
    "cdef double calcMaxbound(pop *SP, int size):\n",
    "    global max_bound\n",
    "    cdef int i, j\n",
    "    SP.size = size\n",
    "    cdef double max_b = SP.ind_array[0].v[0]\n",
    "    for i in range(SP.size):\n",
    "        for j in range(nf):\n",
    "            if max_b < SP.ind_array[i].v[j]:\n",
    "                max_b = SP.ind_array[i].v[j]\n",
    "    if max_b == 0.0:\n",
    "        max_b = 1e-8\n",
    "    max_bound = max_b\n",
    "    return max_b\n",
    "\n",
    "cdef void calcul_weight(pop *SP, int size):\n",
    "    cdef int i, j\n",
    "    for i in range(SP.size):\n",
    "        for j in range(nf):\n",
    "            SP.ind_array[i].v[j] = SP.ind_array[i].f[j] * vector_weight[j]\n",
    "\n",
    "cdef int compute_fitness_and_select(pop *SP, ind *x, int size):\n",
    "    cdef int i, worst\n",
    "    cdef double worst_fit, fit_tmp\n",
    "    SP.size = size\n",
    "    x.fitness = 0\n",
    "    compute_ind_fitness(x, SP)\n",
    "    worst_fit = x.fitness\n",
    "    worst = -1\n",
    "    for i in range(SP.size):\n",
    "        fit_tmp = update_fitness_return(SP.ind_array[i].fitness, calcAddEpsIndicator(x, SP.ind_array[i]))\n",
    "        if fit_tmp > worst_fit:\n",
    "            worst = i\n",
    "            worst_fit = fit_tmp\n",
    "    fit_tmp = x.fitness\n",
    "    if worst == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        for i in range(SP.size):\n",
    "            delete_fitness(SP.ind_array[i], calcAddEpsIndicator(SP.ind_array[worst], SP.ind_array[i]))\n",
    "            update_fitness(SP.ind_array[i], calcAddEpsIndicator(x, SP.ind_array[i]))\n",
    "        delete_fitness(x, calcAddEpsIndicator(SP.ind_array[worst], x))\n",
    "        free_ind(SP.ind_array[worst])\n",
    "        SP.ind_array[worst] = ind_copy(x)\n",
    "        if fit_tmp - worst_fit > smallValue:\n",
    "            return worst\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "cdef np.ndarray get_archive_objs(pop *archive):\n",
    "    cdef int i, j\n",
    "    arr = np.zeros((archive.size, nf), dtype=np.float64)\n",
    "    for i in range(archive.size):\n",
    "        for j in range(nf):\n",
    "            arr[i, j] = archive.ind_array[i].f[j]\n",
    "    return arr\n",
    "\n",
    "cdef np.ndarray get_items(ind *x):\n",
    "    arr = np.zeros(ni, dtype=np.int32)\n",
    "    cdef int i\n",
    "    for i in range(ni):\n",
    "        arr[i] = x.Items[i]\n",
    "    return arr\n",
    "\n",
    "cdef tuple cy_mutation_move(np.ndarray[np.int32_t, ndim=1] items, int ni):\n",
    "    cdef int n_selected = 0, n_unselected = 0, i\n",
    "    for i in range(ni):\n",
    "        if items[i] == 1: n_selected += 1\n",
    "        else: n_unselected += 1\n",
    "    if n_selected == 0 or n_unselected == 0:\n",
    "        return (0, 0)\n",
    "    sel = [i for i in range(ni) if items[i] == 1]\n",
    "    unsel = [i for i in range(ni) if items[i] == 0]\n",
    "    remove_idx = sel[irand(n_selected)]\n",
    "    add_idx = unsel[irand(n_unselected)]\n",
    "    return remove_idx, add_idx\n",
    "\n",
    "cdef tuple cy_local_search_move(np.ndarray[np.int32_t, ndim=1] items, double[:, :] profits, int ni, int nf):\n",
    "    cdef int i\n",
    "    sel = [i for i in range(ni) if items[i] == 1]\n",
    "    unsel = [i for i in range(ni) if items[i] == 0]\n",
    "    if not sel or not unsel:\n",
    "        return (0, 0)\n",
    "    profs_selected = [sum([profits[f, idx] for f in range(nf)]) for idx in sel]\n",
    "    profs_unselected = [sum([profits[f, idx] for f in range(nf)]) for idx in unsel]\n",
    "    remove_idx = sel[np.argmin(profs_selected)]\n",
    "    add_idx = unsel[np.argmax(profs_unselected)]\n",
    "    return remove_idx, add_idx\n",
    "\n",
    "cdef tuple cy_global_search_move(np.ndarray[np.int32_t, ndim=1] items, double[:, :] profits, int ni, int nf):\n",
    "    cdef int i\n",
    "    sel = [i for i in range(ni) if items[i] == 1]\n",
    "    unsel = [i for i in range(ni) if items[i] == 0]\n",
    "    if not sel or not unsel:\n",
    "        return (0, 0)\n",
    "    profs_selected = np.array([sum([profits[f, idx] for f in range(nf)]) for idx in sel], dtype=np.float64) + 1e-9\n",
    "    profs_unselected = np.array([sum([profits[f, idx] for f in range(nf)]) for idx in unsel], dtype=np.float64) + 1e-9\n",
    "    remove_idx = sel[np.random.choice(len(sel), p=profs_selected/np.sum(profs_selected))]\n",
    "    add_idx = unsel[np.random.choice(len(unsel), p=profs_unselected/np.sum(profs_unselected))]\n",
    "    return remove_idx, add_idx\n",
    "\n",
    "def get_profits_np():\n",
    "    global profits, nf, ni\n",
    "    arr = np.zeros((nf, ni), dtype=np.float64)\n",
    "    for f in range(nf):\n",
    "        for i in range(ni):\n",
    "            arr[f, i] = profits[f][i]\n",
    "    return arr\n",
    "\n",
    "cdef void Indicator_local_search1(pop *SP, pop *Sarchive, int size):\n",
    "    cdef ind *x\n",
    "    cdef ind *y\n",
    "    cdef int i_idx, j_idx, r_idx, t_idx, k_idx, l_idx, v_idx, sol_idx, mino_idx, mp_idx, maxp_idx\n",
    "    cdef int consistant, pos_idx, stop_idx, convergence, ii_idx, tmp_pris, tmp_nonpris, taille, feasible, tv_idx, IM_idx\n",
    "    cdef int* remplace = <int *>chk_malloc(L * sizeof(int))\n",
    "    cdef np.ndarray[np.int32_t, ndim=1] items_mv = np.empty(ni, dtype=np.int32)\n",
    "    SP.size = size\n",
    "    extractPtoArchive(SP, Sarchive)\n",
    "    profits_np = get_profits_np()\n",
    "    while True:\n",
    "        convergence = 0\n",
    "        archive_objs = get_archive_objs(Sarchive) if Sarchive.size > 0 else None\n",
    "        loop_start_time = time.time()\n",
    "        for i_idx in range(SP.size):\n",
    "            if not SP.ind_array[i_idx].explored:\n",
    "                x = ind_copy(SP.ind_array[i_idx])\n",
    "                j_idx = 0\n",
    "                while j_idx < x.nombr:\n",
    "                    for l_idx in range(L):\n",
    "                        remplace[l_idx] = 0\n",
    "                    for ii_idx in range(ni):\n",
    "                        items_mv[ii_idx] = x.Items[ii_idx]\n",
    "                    \n",
    "                    move_types = [\"mutation\", \"local_search\", \"global_search\", \"follow\", \"diversity\"]\n",
    "                    mt_idx = irand(5)\n",
    "                    move_type = move_types[mt_idx]\n",
    "                    remove_idx = -1\n",
    "                    add_idx = -1\n",
    "                    agent_move_type = move_type\n",
    "                    agent_success = False\n",
    "                    agent_start_time = time.time()\n",
    "                    \n",
    "                    if move_type == \"mutation\":\n",
    "                        remove_idx, add_idx = cy_mutation_move(items_mv, ni)\n",
    "                    elif move_type == \"local_search\":\n",
    "                        remove_idx, add_idx = cy_local_search_move(items_mv, profits_np, ni, nf)\n",
    "                    elif move_type == \"global_search\":\n",
    "                        remove_idx, add_idx = cy_global_search_move(items_mv, profits_np, ni, nf)\n",
    "                    elif (move_type == \"diversity\" or move_type == \"follow\") and py_agent_manager is not None:\n",
    "                        agent_idx = i_idx % py_agent_manager.num_agents\n",
    "                        agent = py_agent_manager.agents[agent_idx]\n",
    "                        state = {\n",
    "                            \"Items\": [x.Items[ii_idx] for ii_idx in range(ni)],\n",
    "                            \"capa\": [x.capa[ii_idx] for ii_idx in range(nf)],\n",
    "                            \"f\": [x.f[ii_idx] for ii_idx in range(nf)],\n",
    "                        }\n",
    "                        context = {}\n",
    "                        if archive_objs is not None:\n",
    "                            context[\"archive_objs\"] = archive_objs\n",
    "                        try:\n",
    "                            obs = agent.observe(state)\n",
    "                            remove_idx, add_idx = agent.act(obs, context)\n",
    "                            if hasattr(agent, \"last_move_type\"):\n",
    "                                agent_move_type = agent.last_move_type\n",
    "                        except Exception as e:\n",
    "                            print(\"Agent error:\", e)\n",
    "                            remove_idx = -1\n",
    "                            add_idx = -1\n",
    "                            agent_move_type = \"error\"\n",
    "                    \n",
    "                    agent_end_time = time.time()\n",
    "                    if move_stats is not None:\n",
    "                        move_stats[\"total_agent_calls\"] += 1\n",
    "                        move_stats[\"total_time_agent\"] += (agent_end_time - agent_start_time)\n",
    "                        mt = agent_move_type if agent_move_type is not None else \"unknown\"\n",
    "                        if mt not in move_stats[\"move_type_counts\"]:\n",
    "                            move_stats[\"move_type_counts\"][mt] = 0\n",
    "                        move_stats[\"move_type_counts\"][mt] += 1\n",
    "                    \n",
    "                    if remove_idx < 0 or remove_idx >= ni or x.Items[remove_idx] != 1:\n",
    "                        while True:\n",
    "                            mino_idx = irand(ni)\n",
    "                            if x.Items[mino_idx] == 1:\n",
    "                                break\n",
    "                        remove_idx = mino_idx\n",
    "                    if add_idx < 0 or add_idx >= ni or x.Items[add_idx] != 0 or add_idx == remove_idx:\n",
    "                        while True:\n",
    "                            maxp_idx = irand(ni)\n",
    "                            if x.Items[maxp_idx] == 0 and maxp_idx != remove_idx:\n",
    "                                break\n",
    "                        add_idx = maxp_idx\n",
    "                    \n",
    "                    x.Items[remove_idx] = 0\n",
    "                    x.nombr -= 1\n",
    "                    x.nombr_nonpris += 1\n",
    "                    for r_idx in range(nf):\n",
    "                        x.capa[r_idx] -= weights[r_idx][remove_idx]\n",
    "                        x.f[r_idx] -= profits[r_idx][remove_idx]\n",
    "                    \n",
    "                    IM_idx = 0\n",
    "                    taille = 0\n",
    "                    while IM_idx < L:\n",
    "                        item_to_add = add_idx\n",
    "                        if item_to_add < 0 or item_to_add >= ni or x.Items[item_to_add] != 0 or item_to_add == remove_idx:\n",
    "                            while True:\n",
    "                                item_to_add = irand(ni)\n",
    "                                if x.Items[item_to_add] == 0 and item_to_add != remove_idx:\n",
    "                                    break\n",
    "                        consistant = 1\n",
    "                        r_idx = 0\n",
    "                        while r_idx < nf and consistant == 1:\n",
    "                            if x.capa[r_idx] + weights[r_idx][item_to_add] > capacities[r_idx]:\n",
    "                                consistant = 0\n",
    "                            r_idx += 1\n",
    "                        if consistant == 1:\n",
    "                            feasible = 1\n",
    "                            r_idx = 0\n",
    "                            while r_idx < taille and feasible:\n",
    "                                if item_to_add == remplace[r_idx]:\n",
    "                                    feasible = 0\n",
    "                                r_idx += 1\n",
    "                            if feasible == 1:\n",
    "                                remplace[taille] = item_to_add\n",
    "                                taille += 1\n",
    "                                x.Items[item_to_add] = 1\n",
    "                                x.nombr_nonpris -= 1\n",
    "                                x.nombr += 1\n",
    "                                for r_idx in range(nf):\n",
    "                                    x.capa[r_idx] += weights[r_idx][item_to_add]\n",
    "                                    x.f[r_idx] += profits[r_idx][item_to_add]\n",
    "                        IM_idx += 1\n",
    "                    \n",
    "                    for tv_idx in range(nf):\n",
    "                        x.v[tv_idx] = x.f[tv_idx] * vector_weight[tv_idx]\n",
    "                    \n",
    "                    max_bound = calcMaxbound(SP, SP.size)\n",
    "                    sol_idx = compute_fitness_and_select(SP, x, SP.size)\n",
    "                    agent_success = (sol_idx != -1)\n",
    "                    \n",
    "                    if py_agent_manager is not None and (move_type == \"diversity\" or move_type == \"follow\"):\n",
    "                        try:\n",
    "                            agent.report_move_result(agent_move_type, agent_success)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    \n",
    "                    if py_agent_manager is not None:\n",
    "                        agent_idx = i_idx % py_agent_manager.num_agents\n",
    "                        fitness = np.sum([x.f[j_idx] for j_idx in range(nf)])\n",
    "                        py_agent_manager.report_agent_performance(agent_idx, fitness)\n",
    "                    \n",
    "                    if sol_idx != -1:\n",
    "                        j_idx = x.nombr + 1\n",
    "                        if sol_idx > i_idx and i_idx + 1 < SP.size:\n",
    "                            y = SP.ind_array[i_idx + 1]\n",
    "                            SP.ind_array[i_idx + 1] = SP.ind_array[sol_idx]\n",
    "                            SP.ind_array[sol_idx] = y\n",
    "                            i_idx += 1\n",
    "                        break\n",
    "                    elif sol_idx == -1:\n",
    "                        x.Items[remove_idx] = 1\n",
    "                        x.nombr_nonpris -= 1\n",
    "                        x.nombr += 1\n",
    "                        for r_idx in range(nf):\n",
    "                            x.capa[r_idx] += weights[r_idx][remove_idx]\n",
    "                            x.f[r_idx] += profits[r_idx][remove_idx]\n",
    "                        if taille >= 1:\n",
    "                            for r_idx in range(taille):\n",
    "                                x.Items[remplace[r_idx]] = 0\n",
    "                                x.nombr -= 1\n",
    "                                x.nombr_nonpris += 1\n",
    "                                for t_idx in range(nf):\n",
    "                                    x.capa[t_idx] -= weights[t_idx][remplace[r_idx]]\n",
    "                                    x.f[t_idx] -= profits[t_idx][remplace[r_idx]]\n",
    "                                    x.v[t_idx] = x.f[t_idx] * vector_weight[t_idx]\n",
    "                    j_idx += 1\n",
    "                tmp_pris = x.nombr\n",
    "                tmp_nonpris = x.nombr_nonpris\n",
    "                free_ind(x)\n",
    "                if j_idx == tmp_pris:\n",
    "                    SP.ind_array[i_idx].explored = 1\n",
    "        loop_end_time = time.time()\n",
    "        if move_stats is not None:\n",
    "            move_stats[\"total_time_loop\"] += (loop_end_time - loop_start_time)\n",
    "        convergence = extractPtoArchive(SP, Sarchive)\n",
    "        if not convergence:\n",
    "            break\n",
    "    free(remplace)\n",
    "\n",
    "def run_moacp(instance_file, weights_file, nbitems, num_objectives, output_file):\n",
    "    global nf, ni, NBITEMS, alpha, paretoIni, L, nombreLIGNE, nextLn, inv, vector_weight\n",
    "    global capacities, weights, profits, OBJ_Weights\n",
    "    \n",
    "    alpha = 10\n",
    "    paretoIni = 28000\n",
    "    NBL = 25\n",
    "    NRUNS = 3\n",
    "    \n",
    "    reset_move_stats()\n",
    "    \n",
    "    for run in range(1, NRUNS+1):\n",
    "        NBITEMS = nbitems\n",
    "        ni = nbitems\n",
    "        nf = num_objectives\n",
    "        print(f\"RUN {run}/{NRUNS} -- {instance_file.decode()} nbitems={ni} nf={nf} => {output_file}\")\n",
    "        nombreLIGNE = 0\n",
    "        nextLn = 0\n",
    "        inv = 0\n",
    "        seed(run)\n",
    "        loadMOKP(instance_file)\n",
    "        read_weights_file(weights_file)\n",
    "        vector_weight = <double *>chk_malloc(nf * sizeof(double))\n",
    "        P = create_pop(paretoIni, nf)\n",
    "        it = 0\n",
    "        while it < NBL:\n",
    "            solutions = create_pop(alpha, nf)\n",
    "            archive = create_pop(paretoIni, nf)\n",
    "            choose_weight()\n",
    "            P_init_pop(solutions, P, alpha)\n",
    "            extractPtoArchive(solutions, P)\n",
    "            calcul_weight(solutions, alpha)\n",
    "            calcMaxbound(solutions, alpha)\n",
    "            compute_all_fitness(solutions)\n",
    "            Indicator_local_search1(solutions, archive, alpha)\n",
    "            extractPtoArchive(archive, P)\n",
    "            \n",
    "            if py_agent_manager is not None and hasattr(py_agent_manager, \"gses_agent_level\") and it % 10 == 0:\n",
    "                py_agent_manager.gses_agent_level()\n",
    "                if it % 20 == 0 and hasattr(py_agent_manager, \"evolve_with_llm\"):\n",
    "                    py_agent_manager.evolve_with_llm()\n",
    "            \n",
    "            it += 1\n",
    "            complete_free_pop(solutions)\n",
    "            complete_free_pop(archive)\n",
    "        \n",
    "        with open(output_file, \"a\") as fpareto:\n",
    "            fpareto.write(\"\\n\")\n",
    "            for i in range(P.size):\n",
    "                for j in range(nf):\n",
    "                    fpareto.write(f\"{P.ind_array[i].f[j]:.6f} \")\n",
    "                fpareto.write(\"\\n\")\n",
    "        \n",
    "        complete_free_pop(P)\n",
    "        cleanup_globals()\n",
    "        print_move_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296aa16d-fa83-419a-ae39-0af4cb1d52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-generating functions...\n",
      "Error generating LLM response: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=30)\n",
      "Generated function is invalid: Function 'mutation_move' not found in the generated code.\n",
      "Error generating LLM response: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=30)\n",
      "Generated function is invalid: Function 'mutation_move' not found in the generated code.\n",
      "Error generating LLM response: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=30)\n",
      "Generated function is invalid: Function 'local_search_move' not found in the generated code.\n",
      "Error generating LLM response: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=30)\n",
      "Generated function is invalid: Function 'local_search_move' not found in the generated code.\n",
      "Error generating LLM response: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=30)\n",
      "Generated function is invalid: Function 'global_search_move' not found in the generated code.\n",
      "Pre-generated 0 functions\n",
      "Starting optimization...\n",
      "RUN 1/3 -- 250.2.txt nbitems=250 nf=2 => kss5_llm_enhanced.txt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mutation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 6. Run the optimizer with reduced iterations for testing\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting optimization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m \u001b[43mrun_moacp\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_objectives\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m_cython_magic_119f5ba50c096f7852420eb645ce9e84c22e49c7b80c7ce3206e06d34c0e8ddb.pyx:691\u001b[0m, in \u001b[0;36m_cython_magic_119f5ba50c096f7852420eb645ce9e84c22e49c7b80c7ce3206e06d34c0e8ddb.run_moacp\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 114\u001b[0m, in \u001b[0;36mEnhancedAgentPopulationManager.gses_agent_level\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m         child \u001b[38;5;241m=\u001b[39m parent\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# Mutate child\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     new_agents\u001b[38;5;241m.\u001b[39mappend(child)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Update population\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 138\u001b[0m, in \u001b[0;36mEnhancedModularMetaAgent.mutate\u001b[1;34m(self, registry, mutation_rate)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmutate\u001b[39m(\u001b[38;5;28mself\u001b[39m, registry, mutation_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marchitecture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutation_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# Occasionally try to generate new custom moves (if LLM available)\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (ENABLE_LLM \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_generator \u001b[38;5;129;01mand\u001b[39;00m \n\u001b[0;32m    142\u001b[0m         random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevolution_count \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_evolution_count):\n",
      "Cell \u001b[1;32mIn[6], line 83\u001b[0m, in \u001b[0;36mEnhancedAgentArchitecture.mutate\u001b[1;34m(self, registry, mutation_rate)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Remove poor performing move type\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m mutation_rate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(move_types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 83\u001b[0m     success_rates \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_successes[k]\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_counts[k], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m move_types}\n\u001b[0;32m     84\u001b[0m     worst_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(success_rates, key\u001b[38;5;241m=\u001b[39msuccess_rates\u001b[38;5;241m.\u001b[39mget)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success_rates[worst_move] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.2\u001b[39m:  \u001b[38;5;66;03m# Only remove if really poor\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 83\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Remove poor performing move type\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m mutation_rate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(move_types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 83\u001b[0m     success_rates \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove_successes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_counts[k], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m move_types}\n\u001b[0;32m     84\u001b[0m     worst_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(success_rates, key\u001b[38;5;241m=\u001b[39msuccess_rates\u001b[38;5;241m.\u001b[39mget)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success_rates[worst_move] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.2\u001b[39m:  \u001b[38;5;66;03m# Only remove if really poor\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mutation'"
     ]
    }
   ],
   "source": [
    "# --- Parameters and File Names ---\n",
    "nbitems = 250\n",
    "num_objectives = 2\n",
    "instance_file = b\"250.2.txt\"\n",
    "weights_file = b\"Weights_2obj_FQ200.txt\"\n",
    "output_file = \"kss5_llm_enhanced.txt\"\n",
    "random_seed = 42\n",
    "\n",
    "# 1. Load your instance as usual\n",
    "profits = load_profits_from_file(\"250.2.txt\", num_objectives, nbitems)\n",
    "weights = load_weights_from_file(\"250.2.txt\", num_objectives, nbitems)\n",
    "capacities = load_capacities_from_file(\"250.2.txt\", num_objectives, nbitems)\n",
    "\n",
    "# 2. Create LLM function generator\n",
    "llm_generator = LLMFunctionGenerator()\n",
    "\n",
    "# 3. Pre-generate functions before optimization starts\n",
    "print(\"Pre-generating functions...\")\n",
    "llm_generator.pre_generate_functions()\n",
    "\n",
    "# 4. Create the enhanced modular MHRE agent population\n",
    "# Use a smaller number of agents for faster execution\n",
    "agent_manager = EnhancedAgentPopulationManager(\n",
    "    num_agents=5,  # Reduced from 10 to 5\n",
    "    num_items=nbitems,\n",
    "    num_objectives=num_objectives,\n",
    "    profits=profits,\n",
    "    weights=weights,\n",
    "    capacities=capacities,\n",
    "    llm_generator=llm_generator\n",
    ")\n",
    "\n",
    "# 5. Register agent manager with cython\n",
    "set_agent_manager(agent_manager)\n",
    "\n",
    "# 6. Run the optimizer with reduced iterations for testing\n",
    "print(\"Starting optimization...\")\n",
    "run_moacp(instance_file, weights_file, nbitems, num_objectives, output_file)\n",
    "print(\"Optimization completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2c1b8-8f5f-45e5-b264-4b1bdbfea67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_pareto_front(filename):\n",
    "    points = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                points.append([float(x) for x in line.split()])\n",
    "    return np.array(points)\n",
    "\n",
    "def is_dominated(point, others):\n",
    "    \"\"\"Returns True if point is dominated by any row in others\"\"\"\n",
    "    return np.any(np.all(others >= point, axis=1) & np.any(others > point, axis=1))\n",
    "\n",
    "def get_pareto_front(points):\n",
    "    mask = np.ones(len(points), dtype=bool)\n",
    "    for i, p in enumerate(points):\n",
    "        others = np.delete(points, i, axis=0)\n",
    "        if is_dominated(p, others):\n",
    "            mask[i] = False\n",
    "    return points[mask]\n",
    "\n",
    "# Load and merge all runs' points for each result file\n",
    "ref_points = load_pareto_front(\"2502_Resulats.txt\")\n",
    "new_points = load_pareto_front(\"kss5_llm_enhanced.txt\")\n",
    "\n",
    "# Get the true Pareto front for each\n",
    "ref_pareto = get_pareto_front(ref_points)\n",
    "new_pareto = get_pareto_front(new_points)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(ref_pareto[:,0], ref_pareto[:,1], label=\"Reference True Pareto\", alpha=0.7, color='blue')\n",
    "plt.scatter(new_pareto[:,0], new_pareto[:,1], label=\"LLM-Enhanced True Pareto\", alpha=0.7, color='red')\n",
    "plt.xlabel(\"Objective 1\")\n",
    "plt.ylabel(\"Objective 2\")\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Pareto Fronts: Reference vs LLM-Enhanced\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate hypervolume improvement\n",
    "def hypervolume(points, reference_point):\n",
    "    \"\"\"Calculate hypervolume indicator for a set of points.\"\"\"\n",
    "    sorted_points = sorted(points, key=lambda x: x[0])\n",
    "    volume = 0.0\n",
    "    prev_x = reference_point[0]\n",
    "    for point in sorted_points:\n",
    "        width = prev_x - point[0]\n",
    "        height = reference_point[1] - point[1]\n",
    "        volume += width * height\n",
    "        prev_x = point[0]\n",
    "    return volume\n",
    "\n",
    "# Find reference point (max of each objective + 10%)\n",
    "ref_point = np.max(np.vstack([ref_pareto, new_pareto]), axis=0) * 1.1\n",
    "\n",
    "# Calculate hypervolumes\n",
    "ref_hv = hypervolume(ref_pareto, ref_point)\n",
    "new_hv = hypervolume(new_pareto, ref_point)\n",
    "\n",
    "print(f\"Reference Pareto Front Hypervolume: {ref_hv:.2f}\")\n",
    "print(f\"LLM-Enhanced Pareto Front Hypervolume: {new_hv:.2f}\")\n",
    "print(f\"Improvement: {(new_hv - ref_hv) / ref_hv * 100:.2f}%\")\n",
    "\n",
    "# Plot agent performance over generations\n",
    "if hasattr(agent_manager, 'performance_history') and agent_manager.performance_history:\n",
    "    generations = [p['generation'] for p in agent_manager.performance_history]\n",
    "    best_fitness = [p['best_fitness'] for p in agent_manager.performance_history]\n",
    "    avg_fitness = [p['avg_fitness'] for p in agent_manager.performance_history]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(generations, best_fitness, label='Best Fitness', marker='o')\n",
    "    plt.plot(generations, avg_fitness, label='Average Fitness', marker='s')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.title('Agent Population Performance Over Generations')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c70e79-b31d-49de-8a75-bd4aea2dec42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "281399af-893f-43a3-a040-96d7506df436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in a:\\conda\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in a:\\conda\\lib\\site-packages (from scikit-learn) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in a:\\conda\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in a:\\conda\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in a:\\conda\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (a:\\conda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (a:\\conda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (a:\\conda\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9178fb-7429-4e1f-a57c-5f6814ea82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A:\\conda\\envs\\ibmols\\python.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe61c8cf-8b57-4318-aba1-82866693faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\\conda\\envs\\ibmols\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f46c2ef-00d8-483f-a463-cbdce13e5f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\\conda\\envs\\ibmols\\lib\\site-packages\\sklearn\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c0d7d6-191f-4d2d-ab33-6b37f76e6486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4 1.13.1 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy, scipy, sklearn\n",
    "print(numpy.__version__, scipy.__version__, sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac25d38-4d43-48e0-99d9-5d1fbf7b7764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2821c1-c43c-4d1b-aa03-99a10dbb814f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005bb47b-b1ae-4aab-9c1c-eccd0a211bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3', 'created_at': '2025-09-06T17:51:18.9589415Z', 'response': \"A nice simple one!\\n\\nThe function `f` is defined as:\\n```\\ndef f(): return 1\\n```\\nThis is a function that takes no arguments and returns the value `1`.\\n\\nYou can call this function like any other:\\n```\\nresult = f()\\nprint(result)  # Output: 1\\n```\\nNote that there's no parameter list (`()`), which means the function doesn't take any arguments. The `return` statement specifies what value is returned when the function is called. In this case, it's always `1`.\", 'done': True, 'done_reason': 'stop', 'context': [128006, 882, 128007, 271, 755, 282, 4658, 471, 220, 16, 128009, 128006, 78191, 128007, 271, 32, 6555, 4382, 832, 2268, 791, 734, 1595, 69, 63, 374, 4613, 439, 512, 14196, 4077, 755, 282, 4658, 471, 220, 16, 198, 14196, 4077, 2028, 374, 264, 734, 430, 5097, 912, 6105, 323, 4780, 279, 907, 1595, 16, 63438, 2675, 649, 1650, 420, 734, 1093, 904, 1023, 512, 14196, 4077, 1407, 284, 282, 746, 1374, 4556, 8, 220, 674, 9442, 25, 220, 16, 198, 14196, 4077, 9290, 430, 1070, 596, 912, 5852, 1160, 29754, 55358, 705, 902, 3445, 279, 734, 3250, 956, 1935, 904, 6105, 13, 578, 1595, 693, 63, 5224, 30202, 1148, 907, 374, 6052, 994, 279, 734, 374, 2663, 13, 763, 420, 1162, 11, 433, 596, 2744, 1595, 16, 29687], 'total_duration': 68201153400, 'load_duration': 37253043700, 'prompt_eval_count': 16, 'prompt_eval_duration': 2217840700, 'eval_count': 114, 'eval_duration': 28587394000}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "resp = requests.post(\"http://localhost:11434/api/generate\", json={\"model\": \"llama3\", \"prompt\": \"def f(): return 1\", \"stream\": False})\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815102f6-ec1f-434b-abc7-33093dadbc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ibmols)",
   "language": "python",
   "name": "ibmols"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
