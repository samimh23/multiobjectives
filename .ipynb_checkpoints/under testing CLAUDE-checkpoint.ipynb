{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1868a1be-4499-4bef-9d2c-cd06db353fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39d8b6f-2efc-413b-919e-a1ba1d50286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_profits_from_file(filename, num_objectives, num_items):\n",
    "    profits = np.zeros((num_objectives, num_items))\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    idx = 0\n",
    "    idx += 1  # skip header\n",
    "    for obj in range(num_objectives):\n",
    "        idx += 1  # skip capacity line\n",
    "        for item in range(num_items):\n",
    "            idx += 1  # skip \"n:\" line\n",
    "            idx += 1  # skip weight\n",
    "            profit = int(lines[idx])\n",
    "            profits[obj, item] = profit\n",
    "            idx += 1\n",
    "    return profits\n",
    "\n",
    "def load_weights_from_file(filename, num_objectives, num_items):\n",
    "    weights = np.zeros((num_objectives, num_items), dtype=int)\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    idx = 0\n",
    "    idx += 1  # skip header\n",
    "    for obj in range(num_objectives):\n",
    "        idx += 1  # skip capacity line\n",
    "        for item in range(num_items):\n",
    "            idx += 1  # skip \"n:\" line\n",
    "            weight = int(lines[idx])\n",
    "            weights[obj, item] = weight\n",
    "            idx += 2  # skip profit\n",
    "    return weights\n",
    "\n",
    "def load_capacities_from_file(filename, num_objectives, num_items):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    idx = 0\n",
    "    idx += 1  # skip header\n",
    "    capacities = []\n",
    "    for obj in range(num_objectives):\n",
    "        cap = float(lines[idx])\n",
    "        capacities.append(cap)\n",
    "        idx += 1 + 3 * num_items\n",
    "    return np.array(capacities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a65ff4e-1d40-4b8f-93d9-9fdb0508f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup Ollama Llama3\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL_NAME = \"llama3\"\n",
    "\n",
    "def generate_llm_response(system_prompt, user_prompt, max_new_tokens=500):\n",
    "    \"\"\"Generate a response from Ollama Llama3 using the provided prompts.\"\"\"\n",
    "    prompt = f\"System: {system_prompt}\\n\\nUser: {user_prompt}\\n\\nAssistant:\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.6,\n",
    "            \"top_p\": 0.9,\n",
    "            \"num_predict\": max_new_tokens\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(OLLAMA_URL, json=payload)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return result.get(\"response\", \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating LLM response: {e}\")\n",
    "        return \"def mock_function():\\n    pass\"\n",
    "\n",
    "def extract_code_from_response(response):\n",
    "    \"\"\"Extract Python code from LLM response.\"\"\"\n",
    "    markers = [\n",
    "        (\"```python\", \"```\"),\n",
    "        (\"```Python\", \"```\"),\n",
    "        (\"```\", \"```\"),\n",
    "        (\"`\", \"`\")\n",
    "    ]\n",
    "    \n",
    "    for start_marker, end_marker in markers:\n",
    "        start_idx = response.find(start_marker)\n",
    "        if start_idx != -1:\n",
    "            start_idx += len(start_marker)\n",
    "            end_idx = response.find(end_marker, start_idx)\n",
    "            if end_idx != -1:\n",
    "                return response[start_idx:end_idx].strip()\n",
    "    \n",
    "    lines = response.split('\\n')\n",
    "    code_lines = []\n",
    "    in_function = False\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.strip().startswith('def '):\n",
    "            in_function = True\n",
    "            code_lines.append(line)\n",
    "        elif in_function:\n",
    "            if line.strip() and not line.startswith(' ') and not line.startswith('\\t'):\n",
    "                break\n",
    "            code_lines.append(line)\n",
    "    \n",
    "    if code_lines:\n",
    "        return '\\n'.join(code_lines)\n",
    "    \n",
    "    return response.strip()\n",
    "\n",
    "def validate_function(code, function_name, input_args):\n",
    "    \"\"\"Enhanced validation with more thorough checks\"\"\"\n",
    "    try:\n",
    "        namespace = {'np': np}\n",
    "        exec(code, namespace)\n",
    "        \n",
    "        if function_name not in namespace:\n",
    "            return False, f\"Function '{function_name}' not found in the generated code.\"\n",
    "        \n",
    "        func = namespace[function_name]\n",
    "        \n",
    "        # Create dummy inputs\n",
    "        dummy_inputs = []\n",
    "        for arg in input_args:\n",
    "            if isinstance(arg, tuple) and arg[0] == 'array':\n",
    "                dummy_inputs.append(np.zeros(arg[1], dtype=np.int32))\n",
    "            elif isinstance(arg, tuple) and arg[0] == 'array_2d':\n",
    "                dummy_inputs.append(np.zeros(arg[1], dtype=np.float64))\n",
    "            elif isinstance(arg, tuple) and arg[0] == 'dict':\n",
    "                dummy_inputs.append({})\n",
    "            elif isinstance(arg, tuple) and arg[0] == 'float':\n",
    "                dummy_inputs.append(0.1)\n",
    "            else:\n",
    "                dummy_inputs.append(0)\n",
    "        \n",
    "        # Test call\n",
    "        result = func(*dummy_inputs)\n",
    "        \n",
    "        # Check return type\n",
    "        if not isinstance(result, tuple) or len(result) != 2:\n",
    "            return False, f\"Function should return a tuple of two integers, got {type(result)}\"\n",
    "        \n",
    "        # Check if return values are integers\n",
    "        remove_idx, add_idx = result\n",
    "        if not isinstance(remove_idx, int) or not isinstance(add_idx, int):\n",
    "            return False, f\"Function should return integers, got {type(remove_idx)} and {type(add_idx)}\"\n",
    "        \n",
    "        # Check if indices are within reasonable bounds\n",
    "        if remove_idx < 0 or remove_idx >= 250 or add_idx < 0 or add_idx >= 250:\n",
    "            return False, f\"Function returned out-of-bounds indices: {remove_idx}, {add_idx}\"\n",
    "        \n",
    "        return True, \"Function is valid.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Error validating function: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1a9c2d-d4f3-4f16-abc9-c211005b7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    \"\"\"Simple mutation move with proper error handling.\"\"\"\n",
    "    try:\n",
    "        # Convert to list for safe indexing\n",
    "        obs_list = observation.tolist() if hasattr(observation, 'tolist') else list(observation)\n",
    "        selected = [i for i, val in enumerate(obs_list) if val == 1]\n",
    "        unselected = [i for i, val in enumerate(obs_list) if val == 0]\n",
    "        \n",
    "        if not selected or not unselected:\n",
    "            return 0, 0\n",
    "        \n",
    "        remove_idx = int(np.random.choice(selected))\n",
    "        add_idx = int(np.random.choice(unselected))\n",
    "        \n",
    "        return remove_idx, add_idx\n",
    "    except Exception:\n",
    "        return 0, 0\n",
    "\n",
    "def local_search_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    \"\"\"Local search move with proper error handling.\"\"\"\n",
    "    try:\n",
    "        obs_list = observation.tolist() if hasattr(observation, 'tolist') else list(observation)\n",
    "        selected = [i for i, val in enumerate(obs_list) if val == 1]\n",
    "        unselected = [i for i, val in enumerate(obs_list) if val == 0]\n",
    "        \n",
    "        if not selected or not unselected or profits is None:\n",
    "            return 0, 0\n",
    "        \n",
    "        # Calculate total profit for each item\n",
    "        profs_selected = []\n",
    "        for idx in selected:\n",
    "            total_profit = sum(profits[f, idx] for f in range(profits.shape[0]))\n",
    "            profs_selected.append(total_profit)\n",
    "        \n",
    "        profs_unselected = []\n",
    "        for idx in unselected:\n",
    "            total_profit = sum(profits[f, idx] for f in range(profits.shape[0]))\n",
    "            profs_unselected.append(total_profit)\n",
    "        \n",
    "        remove_idx = selected[np.argmin(profs_selected)]\n",
    "        add_idx = unselected[np.argmax(profs_unselected)]\n",
    "        \n",
    "        return int(remove_idx), int(add_idx)\n",
    "    except Exception:\n",
    "        return 0, 0\n",
    "\n",
    "def global_search_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    \"\"\"Global search move with proper error handling.\"\"\"\n",
    "    try:\n",
    "        obs_list = observation.tolist() if hasattr(observation, 'tolist') else list(observation)\n",
    "        selected = [i for i, val in enumerate(obs_list) if val == 1]\n",
    "        unselected = [i for i, val in enumerate(obs_list) if val == 0]\n",
    "        \n",
    "        if not selected or not unselected or profits is None:\n",
    "            return 0, 0\n",
    "        \n",
    "        # Calculate total profit for each item\n",
    "        profs_selected = []\n",
    "        for idx in selected:\n",
    "            total_profit = sum(profits[f, idx] for f in range(profits.shape[0]))\n",
    "            profs_selected.append(total_profit + 1e-9)  # Avoid division by zero\n",
    "        \n",
    "        profs_unselected = []\n",
    "        for idx in unselected:\n",
    "            total_profit = sum(profits[f, idx] for f in range(profits.shape[0]))\n",
    "            profs_unselected.append(total_profit + 1e-9)  # Avoid division by zero\n",
    "        \n",
    "        # Normalize to probabilities\n",
    "        probs_selected = np.array(profs_selected) / np.sum(profs_selected)\n",
    "        probs_unselected = np.array(profs_unselected) / np.sum(profs_unselected)\n",
    "        \n",
    "        remove_idx = np.random.choice(selected, p=probs_selected)\n",
    "        add_idx = np.random.choice(unselected, p=probs_unselected)\n",
    "        \n",
    "        return int(remove_idx), int(add_idx)\n",
    "    except Exception:\n",
    "        return 0, 0\n",
    "\n",
    "def follow_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    \"\"\"Follow move with proper error handling.\"\"\"\n",
    "    try:\n",
    "        if best_observation is None:\n",
    "            return mutation_move(observation, profits, weights, capacities)\n",
    "        \n",
    "        obs_list = observation.tolist() if hasattr(observation, 'tolist') else list(observation)\n",
    "        best_list = best_observation.tolist() if hasattr(best_observation, 'tolist') else list(best_observation)\n",
    "        \n",
    "        # Find items to add and remove\n",
    "        add_candidates = []\n",
    "        remove_candidates = []\n",
    "        \n",
    "        for i in range(len(obs_list)):\n",
    "            if obs_list[i] == 0 and best_list[i] == 1:\n",
    "                add_candidates.append(i)\n",
    "            elif obs_list[i] == 1 and best_list[i] == 0:\n",
    "                remove_candidates.append(i)\n",
    "        \n",
    "        if not add_candidates or not remove_candidates:\n",
    "            return mutation_move(observation, profits, weights, capacities)\n",
    "        \n",
    "        add_idx = int(np.random.choice(add_candidates))\n",
    "        remove_idx = int(np.random.choice(remove_candidates))\n",
    "        \n",
    "        return remove_idx, add_idx\n",
    "    except Exception:\n",
    "        return mutation_move(observation, profits, weights, capacities)\n",
    "\n",
    "def diversity_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "    \"\"\"Diversity move with proper error handling.\"\"\"\n",
    "    try:\n",
    "        obs_list = observation.tolist() if hasattr(observation, 'tolist') else list(observation)\n",
    "        selected = [i for i, val in enumerate(obs_list) if val == 1]\n",
    "        unselected = [i for i, val in enumerate(obs_list) if val == 0]\n",
    "        \n",
    "        if not selected or not unselected or archive_objs is None or profits is None:\n",
    "            return 0, 0\n",
    "        \n",
    "        best_move = None\n",
    "        best_min_dist = -np.inf\n",
    "        \n",
    "        # Try several random moves\n",
    "        for _ in range(3):\n",
    "            remove_idx = int(np.random.choice(selected))\n",
    "            add_idx = int(np.random.choice(unselected))\n",
    "            \n",
    "            # Create candidate solution\n",
    "            candidate = obs_list.copy()\n",
    "            candidate[remove_idx] = 0\n",
    "            candidate[add_idx] = 1\n",
    "            \n",
    "            # Calculate objective values\n",
    "            candidate_objs = []\n",
    "            for f in range(profits.shape[0]):\n",
    "                obj_val = sum(profits[f, i] for i in range(len(candidate)) if candidate[i] == 1)\n",
    "                candidate_objs.append(obj_val)\n",
    "            \n",
    "            # Calculate minimum distance to archive\n",
    "            dists = []\n",
    "            for archive_sol in archive_objs:\n",
    "                dist = np.linalg.norm(np.array(candidate_objs) - np.array(archive_sol))\n",
    "                dists.append(dist)\n",
    "            \n",
    "            min_dist = min(dists) if dists else 0\n",
    "            \n",
    "            if min_dist > best_min_dist:\n",
    "                best_min_dist = min_dist\n",
    "                best_move = (remove_idx, add_idx)\n",
    "        \n",
    "        return best_move if best_move is not None else (0, 0)\n",
    "    except Exception:\n",
    "        return 0, 0\n",
    "\n",
    "# Registry for moves\n",
    "MOVE_REGISTRY = {\n",
    "    \"mutation\": mutation_move,\n",
    "    \"local_search\": local_search_move,\n",
    "    \"global_search\": global_search_move,\n",
    "    \"follow\": follow_move,\n",
    "    \"diversity\": diversity_move,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69791fe-326f-4396-a890-54d9ffbae4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMFunctionGenerator:\n",
    "    \"\"\"Class for generating and evolving heuristic functions using LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.function_cache = {}  # Cache for generated functions\n",
    "        self.generation_count = 0\n",
    "        self.max_generations = 10  # Reduced for performance\n",
    "        self.pre_generated_functions = {}  # Pre-generated functions\n",
    "        self.validation_errors = []  # Track validation errors\n",
    "        \n",
    "    def pre_generate_functions(self):\n",
    "        \"\"\"Pre-generate a diverse set of functions before optimization starts\"\"\"\n",
    "        move_types = [\"mutation\", \"local_search\", \"global_search\", \"follow\", \"diversity\"]\n",
    "        success_count = 0\n",
    "        \n",
    "        for move_type in move_types:\n",
    "            for i in range(3):  # Generate 3 variants per move type\n",
    "                code = self.generate_sub_function(move_type)\n",
    "                if code:\n",
    "                    # Validate the code before storing\n",
    "                    input_args = [('array', 250), ('array_2d', (2, 250)), ('array_2d', (2, 250)), ('array', 2), None, None]\n",
    "                    is_valid, message = validate_function(code, f\"{move_type}_move\", input_args)\n",
    "                    \n",
    "                    if is_valid:\n",
    "                        self.pre_generated_functions[f\"{move_type}_{i}\"] = code\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        print(f\"Validation failed for {move_type}_{i}: {message}\")\n",
    "                        self.validation_errors.append((f\"{move_type}_{i}\", message))\n",
    "                else:\n",
    "                    print(f\"Failed to generate {move_type}_{i}\")\n",
    "        \n",
    "        print(f\"Successfully pre-generated {success_count}/{len(move_types)*3} functions\")\n",
    "        if self.validation_errors:\n",
    "            print(\"Validation errors:\")\n",
    "            for func_name, error in self.validation_errors[:5]:  # Show first 5 errors\n",
    "                print(f\"  {func_name}: {error}\")\n",
    "    \n",
    "    def generate_sub_function(self, function_type, context=None):\n",
    "        \"\"\"Generate a new sub-function using LLM.\"\"\"\n",
    "        if self.generation_count >= self.max_generations:\n",
    "            return None\n",
    "        \n",
    "        cache_key = f\"sub_function_{function_type}_{self.generation_count}\"\n",
    "        if cache_key in self.function_cache:\n",
    "            return self.function_cache[cache_key]\n",
    "        \n",
    "        system_prompt = \"\"\"You are an expert in optimization heuristics for multi-objective knapsack problems.\n",
    "        Generate robust Python code that:\n",
    "        1. Uses integer indices for array access\n",
    "        2. Handles edge cases (empty arrays, division by zero)\n",
    "        3. Returns exactly two integers (remove_idx, add_idx)\n",
    "        4. Includes proper type conversions\n",
    "        5. Has clear error handling\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        Design a Python function for {function_type} move in a multi-objective knapsack problem.\n",
    "        \n",
    "        The function must have this exact signature:\n",
    "        ```python\n",
    "        def {function_type}_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "            # Your implementation here\n",
    "            return remove_idx, add_idx\n",
    "        ```\n",
    "        \n",
    "        Requirements:\n",
    "        - observation: binary numpy array of integers (0 or 1)\n",
    "        - profits: 2D numpy array of floats\n",
    "        - weights: 2D numpy array of integers\n",
    "        - capacities: 1D numpy array of floats\n",
    "        - archive_objs: 2D numpy array of floats (optional)\n",
    "        - best_observation: binary numpy array (optional)\n",
    "        \n",
    "        The function must:\n",
    "        1. Return two integers: remove_idx and add_idx\n",
    "        2. Handle cases where no valid move exists (return 0, 0)\n",
    "        3. Use integer indices for all array access\n",
    "        4. Avoid division by zero by adding epsilon (1e-9)\n",
    "        5. Convert numpy arrays to lists if needed for indexing\n",
    "        6. Validate all indices before use\n",
    "        \n",
    "        Example pattern:\n",
    "        ```python\n",
    "        import numpy as np\n",
    "        \n",
    "        def {function_type}_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "            # Convert to list for safe indexing\n",
    "            obs_list = observation.tolist()\n",
    "            selected = [i for i, val in enumerate(obs_list) if val == 1]\n",
    "            unselected = [i for i, val in enumerate(obs_list) if val == 0]\n",
    "            \n",
    "            if not selected or not unselected:\n",
    "                return 0, 0\n",
    "                \n",
    "            # Your logic here\n",
    "            remove_idx = int(selected[0])\n",
    "            add_idx = int(unselected[0])\n",
    "            \n",
    "            return remove_idx, add_idx\n",
    "        ```\n",
    "        \n",
    "        Generate only the function code, no explanations.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = generate_llm_response(system_prompt, user_prompt)\n",
    "            code = extract_code_from_response(response)\n",
    "            self.generation_count += 1\n",
    "            \n",
    "            # Validate the function\n",
    "            input_args = [('array', 250), ('array_2d', (2, 250)), ('array_2d', (2, 250)), ('array', 2), None, None]\n",
    "            is_valid, message = validate_function(code, f\"{function_type}_move\", input_args)\n",
    "            \n",
    "            if not is_valid:\n",
    "                print(f\"Generated function invalid for {function_type}: {message}\")\n",
    "                return None\n",
    "            \n",
    "            # Store in cache\n",
    "            self.function_cache[cache_key] = code\n",
    "            return code\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating {function_type} function: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def crossover_evolution(self, parent1_code, parent2_code, function_type):\n",
    "        \"\"\"Perform crossover evolution between two parent functions.\"\"\"\n",
    "        if self.generation_count >= self.max_generations:\n",
    "            return parent1_code\n",
    "        \n",
    "        system_prompt = \"\"\"You are an expert in optimization heuristics for multi-objective knapsack problems.\n",
    "        Combine two parent functions to create a better child function that:\n",
    "        1. Maintains integer indexing\n",
    "        2. Handles edge cases properly\n",
    "        3. Avoids division by zero\n",
    "        4. Returns exactly two integers\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        Perform crossover evolution between two {function_type} move functions.\n",
    "        \n",
    "        Parent 1:\n",
    "        ```python\n",
    "        {parent1_code}\n",
    "        ```\n",
    "        \n",
    "        Parent 2:\n",
    "        ```python\n",
    "        {parent2_code}\n",
    "        ```\n",
    "        \n",
    "        Create a new {function_type}_move function that:\n",
    "        1. Combines the best features of both parents\n",
    "        2. Uses safe integer indexing\n",
    "        3. Handles all edge cases\n",
    "        4. Returns exactly two integers (remove_idx, add_idx)\n",
    "        \n",
    "        Return only the Python code for the new function.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = generate_llm_response(system_prompt, user_prompt)\n",
    "            code = extract_code_from_response(response)\n",
    "            self.generation_count += 1\n",
    "            \n",
    "            # Validate the function\n",
    "            input_args = [('array', 250), ('array_2d', (2, 250)), ('array_2d', (2, 250)), ('array', 2), None, None]\n",
    "            is_valid, message = validate_function(code, f\"{function_type}_move\", input_args)\n",
    "            \n",
    "            if not is_valid:\n",
    "                print(f\"Crossover function invalid for {function_type}: {message}\")\n",
    "                return parent1_code\n",
    "            \n",
    "            return code\n",
    "        except Exception as e:\n",
    "            print(f\"Error in crossover evolution for {function_type}: {e}\")\n",
    "            return parent1_code\n",
    "    \n",
    "    def cooperative_evolution(self, sub_function_code, arch_function_code):\n",
    "        \"\"\"Perform cooperative evolution between a sub-function and architecture function.\"\"\"\n",
    "        if self.generation_count >= self.max_generations:\n",
    "            return sub_function_code, arch_function_code\n",
    "        \n",
    "        system_prompt = \"\"\"You are an expert in optimization heuristics for multi-objective knapsack problems.\n",
    "        Improve both functions to work better together:\n",
    "        1. Ensure safe integer operations\n",
    "        2. Handle edge cases properly\n",
    "        3. Avoid division by zero\n",
    "        4. Maintain exact return types\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        Improve these functions to work better together:\n",
    "        \n",
    "        Sub-function:\n",
    "        ```python\n",
    "        {sub_function_code}\n",
    "        ```\n",
    "        \n",
    "        Architecture function:\n",
    "        ```python\n",
    "        {arch_function_code}\n",
    "        ```\n",
    "        \n",
    "        Create improved versions that:\n",
    "        1. Use safe integer operations\n",
    "        2. Handle all edge cases\n",
    "        3. Avoid division by zero (use epsilon)\n",
    "        4. Maintain exact return types\n",
    "        \n",
    "        Return only the Python code for both functions in this format:\n",
    "        ```python\n",
    "        # Sub-function\n",
    "        def sub_function(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\n",
    "            # Implementation\n",
    "            return remove_idx, add_idx\n",
    "        \n",
    "        # Architecture function\n",
    "        def arch_function(move_types, move_counts, move_successes, move_probs, smoothing):\n",
    "            # Implementation\n",
    "            return updated_move_probs\n",
    "        ```\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = generate_llm_response(system_prompt, user_prompt)\n",
    "            code = extract_code_from_response(response)\n",
    "            self.generation_count += 1\n",
    "            \n",
    "            # Extract sub-function and architecture function\n",
    "            sub_start = code.find(\"def sub_function(\")\n",
    "            arch_start = code.find(\"def arch_function(\")\n",
    "            \n",
    "            if sub_start == -1 or arch_start == -1:\n",
    "                print(\"Cooperative evolution failed to generate valid functions\")\n",
    "                return sub_function_code, arch_function_code\n",
    "            \n",
    "            sub_end = code.find(\"\\ndef \", sub_start + 1) if code.find(\"\\ndef \", sub_start + 1) != -1 else len(code)\n",
    "            arch_end = code.find(\"\\ndef \", arch_start + 1) if code.find(\"\\ndef \", arch_start + 1) != -1 else len(code)\n",
    "            \n",
    "            sub_function = code[sub_start:sub_end]\n",
    "            arch_function = code[arch_start:arch_end]\n",
    "            \n",
    "            # Validate both functions\n",
    "            sub_valid, sub_msg = validate_function(sub_function, \"sub_function\", \n",
    "                                              [('array', 250), ('array_2d', (2, 250)), ('array_2d', (2, 250)), ('array', 2), None, None])\n",
    "            \n",
    "            arch_valid, arch_msg = validate_function(arch_function, \"arch_function\", \n",
    "                                              [('list', 5), ('dict',), ('dict',), ('array', 5), ('float',)])\n",
    "            \n",
    "            if not sub_valid or not arch_valid:\n",
    "                print(f\"Cooperative evolution validation failed: sub={sub_msg}, arch={arch_msg}\")\n",
    "                return sub_function_code, arch_function_code\n",
    "            \n",
    "            return sub_function, arch_function\n",
    "        except Exception as e:\n",
    "            print(f\"Error in cooperative evolution: {e}\")\n",
    "            return sub_function_code, arch_function_code\n",
    "    \n",
    "    def architecture_upgrade(self, arch_function_code, performance_feedback):\n",
    "        \"\"\"Upgrade the architecture function based on performance feedback.\"\"\"\n",
    "        if self.generation_count >= self.max_generations:\n",
    "            return arch_function_code\n",
    "        \n",
    "        system_prompt = \"\"\"You are an expert in optimization heuristics for multi-objective knapsack problems.\n",
    "        Upgrade the architecture function to:\n",
    "        1. Use safe numerical operations\n",
    "        2. Handle edge cases properly\n",
    "        3. Avoid division by zero\n",
    "        4. Maintain exact return types\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        Upgrade this architecture function based on performance feedback:\n",
    "        \n",
    "        Current function:\n",
    "        ```python\n",
    "        {arch_function_code}\n",
    "        ```\n",
    "        \n",
    "        Performance feedback:\n",
    "        {performance_feedback}\n",
    "        \n",
    "        Create an improved version that:\n",
    "        1. Uses safe numerical operations (add epsilon to denominators)\n",
    "        2. Handles all edge cases\n",
    "        3. Avoids division by zero\n",
    "        4. Returns the correct array type\n",
    "        \n",
    "        Return only the Python code for the upgraded function.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = generate_llm_response(system_prompt, user_prompt)\n",
    "            code = extract_code_from_response(response)\n",
    "            self.generation_count += 1\n",
    "            \n",
    "            # Validate the function\n",
    "            input_args = [('list', 5), ('dict',), ('dict',), ('array', 5), ('float',)]\n",
    "            is_valid, message = validate_function(code, \"arch_function\", input_args)\n",
    "            \n",
    "            if not is_valid:\n",
    "                print(f\"Architecture upgrade invalid: {message}\")\n",
    "                return arch_function_code\n",
    "            \n",
    "            return code\n",
    "        except Exception as e:\n",
    "            print(f\"Error in architecture upgrade: {e}\")\n",
    "            return arch_function_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8475462-b4c2-428a-9f5a-e4e65797dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAgentArchitecture:\n",
    "    \"\"\"Enhanced architecture function with LLM integration for evolution.\"\"\"\n",
    "    \n",
    "    def __init__(self, move_types, smoothing=0.1, llm_generator=None):\n",
    "        self.move_types = list(move_types)\n",
    "        self.move_counts = {k: 1 for k in self.move_types}\n",
    "        self.move_successes = {k: 1 for k in self.move_types}\n",
    "        self.move_probs = np.ones(len(self.move_types)) / len(self.move_types)\n",
    "        self.smoothing = smoothing\n",
    "        self.llm_generator = llm_generator\n",
    "        self.performance_history = []\n",
    "        self.upgrade_count = 0\n",
    "        \n",
    "    def select_move(self):\n",
    "        idx = np.random.choice(len(self.move_types), p=self.move_probs)\n",
    "        move_type = self.move_types[idx]\n",
    "        return move_type\n",
    "    \n",
    "    def report_move_result(self, move_type, success):\n",
    "        if move_type not in self.move_types:\n",
    "            return\n",
    "        self.move_counts[move_type] += 1\n",
    "        if success:\n",
    "            self.move_successes[move_type] += 1\n",
    "        \n",
    "        # Softmax move adaptation\n",
    "        rates = np.array([self.move_successes[k]/self.move_counts[k] for k in self.move_types], dtype=np.float64)\n",
    "        exp_rates = np.exp(rates / self.smoothing)\n",
    "        new_probs = exp_rates / np.sum(exp_rates)\n",
    "        self.move_probs = 0.5 * self.move_probs + 0.5 * new_probs\n",
    "        self.move_probs = self.move_probs / np.sum(self.move_probs)\n",
    "        \n",
    "        # Record performance for LLM feedback\n",
    "        self.performance_history.append({\n",
    "            'move_type': move_type,\n",
    "            'success': success,\n",
    "            'rates': rates.copy(),\n",
    "            'probs': self.move_probs.copy()\n",
    "        })\n",
    "    \n",
    "    def clone(self):\n",
    "        arch = EnhancedAgentArchitecture(self.move_types, self.smoothing, self.llm_generator)\n",
    "        arch.move_counts = dict(self.move_counts)\n",
    "        arch.move_successes = dict(self.move_successes)\n",
    "        arch.move_probs = np.copy(self.move_probs)\n",
    "        arch.performance_history = list(self.performance_history)\n",
    "        return arch\n",
    "    \n",
    "    def mutate(self, registry, mutation_rate=0.25):\n",
    "        move_types = set(self.move_types)\n",
    "        all_types = set(registry.keys())\n",
    "        \n",
    "        if random.random() < mutation_rate and len(move_types) < len(all_types):\n",
    "            add = random.choice(list(all_types - move_types))\n",
    "            move_types.add(add)\n",
    "        \n",
    "        if random.random() < mutation_rate and len(move_types) > 1:\n",
    "            drop = random.choice(list(move_types))\n",
    "            move_types.remove(drop)\n",
    "        \n",
    "        move_types = list(move_types)\n",
    "        random.shuffle(move_types)\n",
    "        \n",
    "        self.move_types = move_types\n",
    "        \n",
    "        self.move_counts = {k: 1 for k in self.move_types}\n",
    "        self.move_successes = {k: 1 for k in self.move_types}\n",
    "        self.move_probs = np.ones(len(self.move_types)) / len(self.move_types)\n",
    "    \n",
    "    def reflect_and_upgrade(self, performance_history):\n",
    "        \"\"\"Implement true hierarchical reflection as in MHRE\"\"\"\n",
    "        if not self.llm_generator or len(performance_history) < 5:\n",
    "            return False\n",
    "            \n",
    "        move_performance = {}\n",
    "        for move_type in self.move_types:\n",
    "            moves = [p for p in performance_history if p['move_type'] == move_type]\n",
    "            if moves:\n",
    "                success_rate = sum(1 for p in moves if p['success']) / len(moves)\n",
    "                move_performance[move_type] = success_rate\n",
    "        \n",
    "        reflection_prompt = f\"\"\"\n",
    "        Analyze the performance of different move types: {move_performance}\n",
    "        \n",
    "        Current architecture parameters:\n",
    "        - Move probabilities: {dict(zip(self.move_types, self.move_probs))}\n",
    "        - Smoothing factor: {self.smoothing}\n",
    "        \n",
    "        Reflect on how to improve the architecture to better balance exploration and exploitation.\n",
    "        Suggest specific improvements to the architecture function.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            feedback = generate_llm_response(\"You are an optimization expert.\", reflection_prompt)\n",
    "            return self.implement_reflection_feedback(feedback)\n",
    "        except Exception as e:\n",
    "            print(f\"Reflection failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def implement_reflection_feedback(self, feedback):\n",
    "        \"\"\"Implement feedback from LLM reflection\"\"\"\n",
    "        current_code = f\"\"\"\n",
    "def arch_function(move_types, move_counts, move_successes, move_probs, smoothing):\n",
    "    rates = np.array([move_successes[k]/move_counts[k] for k in move_types], dtype=np.float64)\n",
    "    exp_rates = np.exp(rates / smoothing)\n",
    "    new_probs = exp_rates / np.sum(exp_rates)\n",
    "    updated_move_probs = 0.5 * move_probs + 0.5 * new_probs\n",
    "    updated_move_probs = updated_move_probs / np.sum(updated_move_probs)\n",
    "    return updated_move_probs\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            upgraded_code = self.llm_generator.architecture_upgrade(current_code, feedback)\n",
    "            \n",
    "            input_args = [('list', 5), ('dict',), ('dict',), ('array', 5), ('float',)]\n",
    "            is_valid, message = validate_function(upgraded_code, \"arch_function\", input_args)\n",
    "            \n",
    "            if is_valid:\n",
    "                namespace = {}\n",
    "                exec(upgraded_code, namespace)\n",
    "                self._upgraded_arch_function = namespace[\"arch_function\"]\n",
    "                self.upgrade_count += 1\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to implement reflection: {e}\")\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def upgrade_with_llm(self):\n",
    "        \"\"\"Upgrade the architecture using LLM based on performance history.\"\"\"\n",
    "        if not self.llm_generator or len(self.performance_history) < 10 or self.upgrade_count >= 3:\n",
    "            return False\n",
    "        \n",
    "        success_rates = {}\n",
    "        for move_type in self.move_types:\n",
    "            moves = [p for p in self.performance_history if p['move_type'] == move_type]\n",
    "            if moves:\n",
    "                success_count = sum(1 for p in moves if p['success'])\n",
    "                success_rates[move_type] = success_count / len(moves)\n",
    "            else:\n",
    "                success_rates[move_type] = 0.5\n",
    "        \n",
    "        feedback = f\"Current success rates: {success_rates}\\n\"\n",
    "        feedback += f\"Move probabilities: {dict(zip(self.move_types, self.move_probs))}\\n\"\n",
    "        \n",
    "        low_success_moves = [mt for mt, sr in success_rates.items() if sr < 0.3]\n",
    "        high_success_moves = [mt for mt, sr in success_rates.items() if sr > 0.7]\n",
    "        \n",
    "        if low_success_moves:\n",
    "            feedback += f\"Moves with low success rates: {low_success_moves}\\n\"\n",
    "        if high_success_moves:\n",
    "            feedback += f\"Moves with high success rates: {high_success_moves}\\n\"\n",
    "        \n",
    "        current_code = f\"\"\"\n",
    "def arch_function(move_types, move_counts, move_successes, move_probs, smoothing):\n",
    "    rates = np.array([move_successes[k]/move_counts[k] for k in move_types], dtype=np.float64)\n",
    "    exp_rates = np.exp(rates / smoothing)\n",
    "    new_probs = exp_rates / np.sum(exp_rates)\n",
    "    updated_move_probs = 0.5 * move_probs + 0.5 * new_probs\n",
    "    updated_move_probs = updated_move_probs / np.sum(updated_move_probs)\n",
    "    return updated_move_probs\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            upgraded_code = self.llm_generator.architecture_upgrade(current_code, feedback)\n",
    "            \n",
    "            input_args = [('list', 5), ('dict',), ('dict',), ('array', 5), ('float',)]\n",
    "            is_valid, message = validate_function(upgraded_code, \"arch_function\", input_args)\n",
    "            \n",
    "            if is_valid:\n",
    "                namespace = {}\n",
    "                exec(upgraded_code, namespace)\n",
    "                self._upgraded_arch_function = namespace[\"arch_function\"]\n",
    "                self.upgrade_count += 1\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"Architecture upgrade failed: {str(e)}\")\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b733bb9-59e4-455d-8d25-1efad2790a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedModularMetaAgent:\n",
    "    \"\"\"Enhanced modular agent with LLM integration for move function evolution.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_items, num_objectives, profits, weights, capacities, \n",
    "                 move_types=None, smoothing=0.1, llm_generator=None):\n",
    "        self.num_items = num_items\n",
    "        self.num_objectives = num_objectives\n",
    "        self.profits = profits\n",
    "        self.weights = weights\n",
    "        self.capacities = capacities\n",
    "        self.llm_generator = llm_generator\n",
    "        self.custom_moves = {}  # Store custom move functions\n",
    "        self.evolution_count = 0\n",
    "        \n",
    "        self.architecture = EnhancedAgentArchitecture(\n",
    "            move_types if move_types else list(MOVE_REGISTRY.keys()), \n",
    "            smoothing=smoothing,\n",
    "            llm_generator=llm_generator\n",
    "        )\n",
    "        \n",
    "        self.best_observation = None\n",
    "        self.last_move_type = None\n",
    "        self.performance_history = []\n",
    "    \n",
    "    def observe(self, state):\n",
    "        return np.array(state[\"Items\"], dtype=np.int32)\n",
    "    \n",
    "    def act(self, observation, context=None):\n",
    "        archive_objs = context.get(\"archive_objs\") if context else None\n",
    "        best_obs = self.best_observation\n",
    "        \n",
    "        for _ in range(3):\n",
    "            move_type = self.architecture.select_move()\n",
    "            \n",
    "            if move_type in self.custom_moves:\n",
    "                move_fn = self.custom_moves[move_type]\n",
    "            elif move_type in MOVE_REGISTRY:\n",
    "                move_fn = MOVE_REGISTRY[move_type]\n",
    "            else:\n",
    "                if self.llm_generator and self.evolution_count < 5:\n",
    "                    try:\n",
    "                        code = self.llm_generator.generate_sub_function(move_type)\n",
    "                        if code:\n",
    "                            namespace = {}\n",
    "                            exec(code, namespace)\n",
    "                            move_fn = namespace[f\"{move_type}_move\"]\n",
    "                            self.custom_moves[move_type] = move_fn\n",
    "                            self.evolution_count += 1\n",
    "                        else:\n",
    "                            move_fn = MOVE_REGISTRY.get(\"mutation\", mutation_move)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to generate move function: {str(e)}\")\n",
    "                        move_fn = MOVE_REGISTRY.get(\"mutation\", mutation_move)\n",
    "                else:\n",
    "                    move_fn = MOVE_REGISTRY.get(\"mutation\", mutation_move)\n",
    "            \n",
    "            try:\n",
    "                move = move_fn(\n",
    "                    observation, self.profits, self.weights, self.capacities,\n",
    "                    archive_objs=archive_objs, best_observation=best_obs\n",
    "                )\n",
    "                if self._is_feasible(observation, move):\n",
    "                    self.last_move_type = move_type\n",
    "                    return move\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing move {move_type}: {str(e)}\")\n",
    "        \n",
    "        move = mutation_move(observation, self.profits, self.weights, self.capacities)\n",
    "        self.last_move_type = \"mutation\"\n",
    "        return move\n",
    "    \n",
    "    def report_move_result(self, move_type, success):\n",
    "        if move_type is None:\n",
    "            move_type = self.last_move_type\n",
    "        self.architecture.report_move_result(move_type, success)\n",
    "        \n",
    "        self.performance_history.append({\n",
    "            'move_type': move_type,\n",
    "            'success': success,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "    \n",
    "    def update_best(self, observation):\n",
    "        self.best_observation = observation.copy()\n",
    "    \n",
    "    def _is_feasible(self, observation, move):\n",
    "        if self.weights is None or self.capacities is None or move is None:\n",
    "            return True\n",
    "        \n",
    "        remove_idx, add_idx = move\n",
    "        if remove_idx == add_idx:\n",
    "            return False\n",
    "        \n",
    "        items = observation.copy()\n",
    "        if items[remove_idx] == 0 or items[add_idx] == 1:\n",
    "            return False\n",
    "        \n",
    "        items[remove_idx] = 0\n",
    "        items[add_idx] = 1\n",
    "        total_weights = np.sum(self.weights * items, axis=1)\n",
    "        feasible = np.all(total_weights <= self.capacities)\n",
    "        return feasible\n",
    "    \n",
    "    def clone(self):\n",
    "        agent = EnhancedModularMetaAgent(\n",
    "            self.num_items, self.num_objectives, self.profits, self.weights, self.capacities,\n",
    "            move_types=self.architecture.move_types,\n",
    "            smoothing=self.architecture.smoothing,\n",
    "            llm_generator=self.llm_generator\n",
    "        )\n",
    "        \n",
    "        agent.architecture = self.architecture.clone()\n",
    "        agent.custom_moves = dict(self.custom_moves)\n",
    "        agent.evolution_count = self.evolution_count\n",
    "        \n",
    "        if self.best_observation is not None:\n",
    "            agent.best_observation = self.best_observation.copy()\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    def mutate(self, registry, mutation_rate=0.25):\n",
    "        self.architecture.mutate(registry, mutation_rate=mutation_rate)\n",
    "        \n",
    "        if self.llm_generator and random.random() < 0.2 and self.evolution_count < 5:\n",
    "            move_type = random.choice(self.architecture.move_types)\n",
    "            try:\n",
    "                code = self.llm_generator.generate_sub_function(move_type)\n",
    "                if code:\n",
    "                    namespace = {}\n",
    "                    exec(code, namespace)\n",
    "                    self.custom_moves[move_type] = namespace[f\"{move_type}_move\"]\n",
    "                    self.evolution_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to generate new move function: {str(e)}\")\n",
    "    \n",
    "    def evolve_with_llm(self, other_agent=None):\n",
    "        \"\"\"Evolve the agent using LLM-based crossover or cooperative evolution.\"\"\"\n",
    "        if not self.llm_generator or self.evolution_count >= 5:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            if other_agent:\n",
    "                if random.random() < 0.5:\n",
    "                    move_type = random.choice(self.architecture.move_types)\n",
    "                    \n",
    "                    if move_type in self.custom_moves and move_type in other_agent.custom_moves:\n",
    "                        parent1_code = f\"def {move_type}_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\\n    # Custom implementation\\n    pass\"\n",
    "                        parent2_code = f\"def {move_type}_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\\n    # Custom implementation\\n    pass\"\n",
    "                        \n",
    "                        new_code = self.llm_generator.crossover_evolution(parent1_code, parent2_code, move_type)\n",
    "                        \n",
    "                        input_args = [('array', 250), ('array_2d', (2, 250)), ('array_2d', (2, 250)), ('array', 2), None, None]\n",
    "                        is_valid, message = validate_function(new_code, f\"{move_type}_move\", input_args)\n",
    "                        \n",
    "                        if is_valid:\n",
    "                            namespace = {}\n",
    "                            exec(new_code, namespace)\n",
    "                            self.custom_moves[move_type] = namespace[f\"{move_type}_move\"]\n",
    "                            self.evolution_count += 1\n",
    "                            return True\n",
    "                else:\n",
    "                    if self.custom_moves:\n",
    "                        move_type = random.choice(list(self.custom_moves.keys()))\n",
    "                        move_code = f\"def {move_type}_move(observation, profits, weights, capacities, archive_objs=None, best_observation=None):\\n    # Custom implementation\\n    pass\"\n",
    "                        \n",
    "                        arch_code = \"\"\"\n",
    "def arch_function(move_types, move_counts, move_successes, move_probs, smoothing):\n",
    "    rates = np.array([move_successes[k]/move_counts[k] for k in move_types], dtype=np.float64)\n",
    "    exp_rates = np.exp(rates / smoothing)\n",
    "    new_probs = exp_rates / np.sum(exp_rates)\n",
    "    updated_move_probs = 0.5 * move_probs + 0.5 * new_probs\n",
    "    updated_move_probs = updated_move_probs / np.sum(updated_move_probs)\n",
    "    return updated_move_probs\n",
    "\"\"\"\n",
    "                        \n",
    "                        new_move_code, new_arch_code = self.llm_generator.cooperative_evolution(move_code, arch_code)\n",
    "                        \n",
    "                        move_valid, move_msg = validate_function(new_move_code, f\"{move_type}_move\", \n",
    "                                                                [('array', 250), ('array_2d', (2, 250)), ('array_2d', (2, 250)), ('array', 2), None, None])\n",
    "                        \n",
    "                        arch_valid, arch_msg = validate_function(new_arch_code, \"arch_function\", \n",
    "                                                              [('list', 5), ('dict',), ('dict',), ('array', 5), ('float',)])\n",
    "                        \n",
    "                        if move_valid and arch_valid:\n",
    "                            namespace = {}\n",
    "                            exec(new_move_code, namespace)\n",
    "                            self.custom_moves[move_type] = namespace[f\"{move_type}_move\"]\n",
    "                            \n",
    "                            exec(new_arch_code, namespace)\n",
    "                            self.architecture._upgraded_arch_function = namespace[\"arch_function\"]\n",
    "                            self.evolution_count += 1\n",
    "                            return True\n",
    "            else:\n",
    "                if len(self.architecture.performance_history) >= 10:\n",
    "                    if self.architecture.upgrade_with_llm():\n",
    "                        self.evolution_count += 1\n",
    "                        return True\n",
    "        except Exception as e:\n",
    "            print(f\"LLM evolution failed: {str(e)}\")\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e990ec1c-c30b-4675-ba9c-9f76d54b9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedAgentPopulationManager:\n",
    "    \"\"\"Enhanced population manager with LLM-based GSES cycle.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_agents, num_items, num_objectives, profits, weights, capacities, llm_generator=None):\n",
    "        self.num_agents = num_agents\n",
    "        self.llm_generator = llm_generator\n",
    "        self.registry = MOVE_REGISTRY\n",
    "        self.evolution_count = 0\n",
    "        \n",
    "        self.agents = [\n",
    "            EnhancedModularMetaAgent(\n",
    "                num_items, num_objectives, profits, weights, capacities,\n",
    "                move_types=random.sample(list(MOVE_REGISTRY.keys()), k=random.randint(2, len(MOVE_REGISTRY))),\n",
    "                llm_generator=llm_generator\n",
    "            )\n",
    "            for _ in range(num_agents)\n",
    "        ]\n",
    "        \n",
    "        self.agent_stats = [ {\"fitness_sum\": 0.0, \"moves\": 0} for _ in range(num_agents) ]\n",
    "        self.generation = 0\n",
    "        self.performance_history = []\n",
    "    \n",
    "    def select_agent_for_solution(self, solution_idx):\n",
    "        return self.agents[solution_idx % self.num_agents]\n",
    "    \n",
    "    def report_agent_performance(self, agent_idx, solution_fitness):\n",
    "        self.agent_stats[agent_idx][\"fitness_sum\"] += solution_fitness\n",
    "        self.agent_stats[agent_idx][\"moves\"] += 1\n",
    "    \n",
    "    def gses_agent_level(self):\n",
    "        \"\"\"Perform the GSES cycle at the agent level.\"\"\"\n",
    "        avg_fitness = [s[\"fitness_sum\"]/s[\"moves\"] if s[\"moves\"] > 0 else -1e9 for s in self.agent_stats]\n",
    "        \n",
    "        sorted_idx = np.argsort(-np.array(avg_fitness))\n",
    "        survivors = [self.agents[i] for i in sorted_idx[:max(2, self.num_agents//2)]]\n",
    "        \n",
    "        self.performance_history.append({\n",
    "            'generation': self.generation,\n",
    "            'best_fitness': max(avg_fitness),\n",
    "            'avg_fitness': np.mean(avg_fitness),\n",
    "            'num_survivors': len(survivors)\n",
    "        })\n",
    "        \n",
    "        new_agents = []\n",
    "        while len(new_agents) + len(survivors) < self.num_agents:\n",
    "            if random.random() < 0.7 and len(survivors) >= 2:\n",
    "                parent1, parent2 = random.sample(survivors, 2)\n",
    "                child = parent1.clone()\n",
    "                \n",
    "                if self.llm_generator and random.random() < 0.3 and self.evolution_count < 10:\n",
    "                    if child.evolve_with_llm(parent2):\n",
    "                        self.evolution_count += 1\n",
    "                else:\n",
    "                    moves1 = set(parent1.architecture.move_types)\n",
    "                    moves2 = set(parent2.architecture.move_types)\n",
    "                    moves_child = list(moves1 | moves2)\n",
    "                    \n",
    "                    if len(moves_child) > 2:\n",
    "                        moves_child = random.sample(moves_child, k=random.randint(2, len(moves_child)))\n",
    "                    \n",
    "                    child.architecture.move_types = moves_child\n",
    "                    child.architecture.move_counts = {k: 1 for k in moves_child}\n",
    "                    child.architecture.move_successes = {k: 1 for k in moves_child}\n",
    "                    child.architecture.move_probs = np.ones(len(moves_child)) / len(moves_child)\n",
    "                \n",
    "                child.mutate(self.registry, mutation_rate=0.25)\n",
    "                new_agents.append(child)\n",
    "            else:\n",
    "                parent = random.choice(survivors)\n",
    "                child = parent.clone()\n",
    "                child.mutate(self.registry, mutation_rate=0.5)\n",
    "                new_agents.append(child)\n",
    "        \n",
    "        self.agents = survivors + new_agents\n",
    "        self.agent_stats = [ {\"fitness_sum\": 0.0, \"moves\": 0} for _ in range(self.num_agents) ]\n",
    "        self.generation += 1\n",
    "        \n",
    "        print(f\"Generation {self.generation}: Best fitness = {max(avg_fitness):.2f}, Avg fitness = {np.mean(avg_fitness):.2f}\")\n",
    "    \n",
    "    def evolve_with_llm(self):\n",
    "        \"\"\"Perform LLM-based evolution on the population.\"\"\"\n",
    "        if not self.llm_generator or self.evolution_count >= 10:\n",
    "            return\n",
    "        \n",
    "        for agent in self.agents:\n",
    "            if random.random() < 0.2:\n",
    "                if agent.evolve_with_llm():\n",
    "                    self.evolution_count += 1\n",
    "        \n",
    "        if len(self.agents) >= 2:\n",
    "            num_pairs = min(3, len(self.agents) // 2)\n",
    "            for _ in range(num_pairs):\n",
    "                agent1, agent2 = random.sample(self.agents, 2)\n",
    "                if agent1.evolve_with_llm(agent2):\n",
    "                    self.evolution_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e3226bd-cae0-4458-af34-5458eccfc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.stdlib cimport malloc, free, srand, rand\n",
    "from libc.string cimport memset\n",
    "from libc.math cimport exp\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import time\n",
    "\n",
    "cdef struct ind:\n",
    "    int nombr_nonpris\n",
    "    int nombr\n",
    "    int rank\n",
    "    float fitnessbest\n",
    "    float fitness\n",
    "    int explored\n",
    "    double *f\n",
    "    double *capa\n",
    "    double *v\n",
    "    int *d\n",
    "    int *Items\n",
    "\n",
    "cdef struct pop:\n",
    "    int size\n",
    "    int maxsize\n",
    "    ind **ind_array\n",
    "\n",
    "cdef int NBITEMS = 250\n",
    "cdef int ni = 250\n",
    "cdef int L = 5\n",
    "cdef double LARGE = 10e50\n",
    "cdef float smallValue = 0.0000001\n",
    "cdef double kappa = 0.05\n",
    "cdef int alpha = 10\n",
    "cdef int paretoIni = 28000\n",
    "cdef int nf = 2\n",
    "cdef double *capacities = NULL\n",
    "cdef int **weights = NULL\n",
    "cdef int **profits = NULL\n",
    "cdef double *vector_weight = NULL\n",
    "cdef double max_bound = 0.0\n",
    "cdef double **OBJ_Weights = NULL\n",
    "cdef int nombreLIGNE = 0\n",
    "cdef int nextLn = 0\n",
    "cdef int inv = 0\n",
    "cdef int OBJ_Weights_lines = 0\n",
    "\n",
    "cdef public object py_agent_manager = None\n",
    "cdef public object move_stats = None\n",
    "\n",
    "def set_agent_manager(agent_manager):\n",
    "    global py_agent_manager\n",
    "    py_agent_manager = agent_manager\n",
    "\n",
    "def reset_move_stats():\n",
    "    global move_stats\n",
    "    move_stats = {\"total_agent_calls\": 0, \"move_type_counts\": {}, \"total_time_agent\": 0.0, \"total_time_loop\": 0.0}\n",
    "\n",
    "def print_move_stats():\n",
    "    print(\"\\n=== AGENT MOVE PROFILE ===\")\n",
    "    print(\"Total agent calls:\", move_stats[\"total_agent_calls\"])\n",
    "    print(\"Move type counts:\", move_stats[\"move_type_counts\"])\n",
    "    print(\"Total agent time (sec):\", move_stats[\"total_time_agent\"])\n",
    "    print(\"Total loop time (sec):\", move_stats[\"total_time_loop\"])\n",
    "    if move_stats[\"total_agent_calls\"] > 0:\n",
    "        print(\"Avg agent call time (ms):\", 1000.0 * move_stats[\"total_time_agent\"] / move_stats[\"total_agent_calls\"])\n",
    "\n",
    "def seed(int x):\n",
    "    srand(x)\n",
    "\n",
    "cdef int irand(int range_val):\n",
    "    return rand() % range_val\n",
    "\n",
    "cdef void *chk_malloc(size_t size):\n",
    "    cdef void *return_value = malloc(size)\n",
    "    if return_value == NULL:\n",
    "        raise MemoryError(\"Out of memory.\")\n",
    "    memset(return_value, 0, size)\n",
    "    return return_value\n",
    "\n",
    "cdef pop *create_pop(int maxsize, int nf):\n",
    "    cdef int i\n",
    "    cdef pop *pp = <pop *>chk_malloc(sizeof(pop))\n",
    "    pp.size = 0\n",
    "    pp.maxsize = maxsize\n",
    "    pp.ind_array = <ind **>chk_malloc(maxsize * sizeof(void*))\n",
    "    for i in range(maxsize):\n",
    "        pp.ind_array[i] = NULL\n",
    "    return pp\n",
    "\n",
    "cdef ind *create_ind(int nf):\n",
    "    cdef int i\n",
    "    cdef ind *p_ind = <ind *>chk_malloc(sizeof(ind))\n",
    "    p_ind.nombr_nonpris = 0\n",
    "    p_ind.nombr = 0\n",
    "    p_ind.rank = 0\n",
    "    p_ind.fitnessbest = -1.0\n",
    "    p_ind.fitness = -1.0\n",
    "    p_ind.explored = 0\n",
    "    p_ind.f = <double *>chk_malloc(nf * sizeof(double))\n",
    "    p_ind.capa = <double *>chk_malloc(nf * sizeof(double))\n",
    "    p_ind.v = <double *>chk_malloc(nf * sizeof(double))\n",
    "    p_ind.d = <int *>chk_malloc(ni * sizeof(int))\n",
    "    p_ind.Items = <int *>chk_malloc(ni * sizeof(int))\n",
    "    for i in range(ni):\n",
    "        p_ind.Items[i] = 0\n",
    "        p_ind.d[i] = 0\n",
    "    for i in range(nf):\n",
    "        p_ind.f[i] = 0.0\n",
    "        p_ind.capa[i] = 0.0\n",
    "        p_ind.v[i] = 0.0\n",
    "    return p_ind\n",
    "\n",
    "cdef ind *ind_copy(ind *i):\n",
    "    cdef ind *p_ind = create_ind(nf)\n",
    "    cdef int k\n",
    "    p_ind.nombr_nonpris = i.nombr_nonpris\n",
    "    p_ind.nombr = i.nombr\n",
    "    p_ind.rank = i.rank\n",
    "    p_ind.fitnessbest = i.fitnessbest\n",
    "    p_ind.fitness = i.fitness\n",
    "    p_ind.explored = i.explored\n",
    "    for k in range(nf):\n",
    "        p_ind.f[k] = i.f[k]\n",
    "        p_ind.v[k] = i.v[k]\n",
    "        p_ind.capa[k] = i.capa[k]\n",
    "    for k in range(ni):\n",
    "        p_ind.d[k] = i.d[k]\n",
    "        p_ind.Items[k] = i.Items[k]\n",
    "    return p_ind\n",
    "\n",
    "cdef void free_ind(ind *p_ind):\n",
    "    if p_ind != NULL:\n",
    "        free(p_ind.d)\n",
    "        free(p_ind.f)\n",
    "        free(p_ind.capa)\n",
    "        free(p_ind.v)\n",
    "        free(p_ind.Items)\n",
    "        free(p_ind)\n",
    "\n",
    "cdef void complete_free_pop(pop *pp):\n",
    "    cdef int i\n",
    "    if pp != NULL:\n",
    "        if pp.ind_array != NULL:\n",
    "            for i in range(pp.size):\n",
    "                if pp.ind_array[i] != NULL:\n",
    "                    free_ind(pp.ind_array[i])\n",
    "                    pp.ind_array[i] = NULL\n",
    "            free(pp.ind_array)\n",
    "        free(pp)\n",
    "\n",
    "cdef void cleanup_globals():\n",
    "    global capacities, weights, profits, vector_weight, OBJ_Weights, OBJ_Weights_lines, nf, ni\n",
    "    if capacities != NULL:\n",
    "        free(capacities)\n",
    "        capacities = NULL\n",
    "    if weights != NULL:\n",
    "        for i in range(nf):\n",
    "            if weights[i] != NULL:\n",
    "                free(weights[i])\n",
    "        free(weights)\n",
    "        weights = NULL\n",
    "    if profits != NULL:\n",
    "        for i in range(nf):\n",
    "            if profits[i] != NULL:\n",
    "                free(profits[i])\n",
    "        free(profits)\n",
    "        profits = NULL\n",
    "    if vector_weight != NULL:\n",
    "        free(vector_weight)\n",
    "        vector_weight = NULL\n",
    "    if OBJ_Weights != NULL:\n",
    "        for i in range(nf):\n",
    "            if OBJ_Weights[i] != NULL:\n",
    "                free(OBJ_Weights[i])\n",
    "        free(OBJ_Weights)\n",
    "        OBJ_Weights = NULL\n",
    "    OBJ_Weights_lines = 0\n",
    "    nf = 0\n",
    "    ni = 0\n",
    "\n",
    "cdef int non_dominated(ind *p_ind_a, ind *p_ind_b):\n",
    "    cdef int i\n",
    "    cdef int a_is_good = -1\n",
    "    cdef int equal = 1\n",
    "    for i in range(nf):\n",
    "        if p_ind_a.f[i] > p_ind_b.f[i]:\n",
    "            a_is_good = 1\n",
    "        if p_ind_a.f[i] != p_ind_b.f[i]:\n",
    "            equal = 0\n",
    "    if equal:\n",
    "        return 0\n",
    "    return a_is_good\n",
    "\n",
    "cdef double calcAddEpsIndicator(ind *p_ind_a, ind *p_ind_b):\n",
    "    global max_bound\n",
    "    cdef int i\n",
    "    cdef double eps\n",
    "    cdef double temp_eps\n",
    "    if max_bound == 0.0:\n",
    "        max_bound = 1e-8\n",
    "    eps = (p_ind_a.v[0]/max_bound)-(p_ind_b.v[0]/max_bound)\n",
    "    for i in range(1, nf):\n",
    "        temp_eps = (p_ind_a.v[i]/max_bound)-(p_ind_b.v[i]/max_bound)\n",
    "        if temp_eps > eps:\n",
    "            eps = temp_eps\n",
    "    return eps\n",
    "\n",
    "cdef void init_fitness(ind *x):\n",
    "    x.fitness = 0.0\n",
    "\n",
    "cdef void update_fitness(ind *x, double I):\n",
    "    x.fitness -= exp(-I / kappa)\n",
    "\n",
    "cdef double update_fitness_return(double f, double I):\n",
    "    return f - exp(-I / kappa)\n",
    "\n",
    "cdef int delete_fitness(ind *x, double I):\n",
    "    x.fitness += exp(-I / kappa)\n",
    "    return 0\n",
    "\n",
    "cdef void compute_ind_fitness(ind *x, pop *SP):\n",
    "    cdef int j\n",
    "    init_fitness(x)\n",
    "    for j in range(SP.size):\n",
    "        if SP.ind_array[j] != x:\n",
    "            update_fitness(x, calcAddEpsIndicator(SP.ind_array[j], x))\n",
    "\n",
    "cdef void compute_all_fitness(pop *SP):\n",
    "    cdef int i\n",
    "    for i in range(SP.size):\n",
    "        compute_ind_fitness(SP.ind_array[i], SP)\n",
    "\n",
    "cdef void loadMOKP(char *filename):\n",
    "    global nf, ni, capacities, weights, profits\n",
    "    cdef int i, f\n",
    "    with open(filename.decode(), \"r\") as source:\n",
    "        _nf, _ni = [int(x) for x in source.readline().split()]\n",
    "        nf = _nf\n",
    "        ni = _ni\n",
    "        capacities = <double *>chk_malloc(nf * sizeof(double))\n",
    "        weights = <int **>chk_malloc(nf * sizeof(void*))\n",
    "        profits = <int **>chk_malloc(nf * sizeof(void*))\n",
    "        for f in range(nf):\n",
    "            capacities[f] = float(source.readline().strip())\n",
    "            weights[f] = <int *>chk_malloc(ni * sizeof(int))\n",
    "            profits[f] = <int *>chk_malloc(ni * sizeof(int))\n",
    "            for i in range(ni):\n",
    "                source.readline()\n",
    "                weights[f][i] = int(source.readline().strip())\n",
    "                profits[f][i] = int(source.readline().strip())\n",
    "\n",
    "cdef void read_weights_file(char *filename):\n",
    "    global OBJ_Weights, nombreLIGNE, nf, OBJ_Weights_lines\n",
    "    cdef int i, j, nlines\n",
    "    with open(filename.decode(), \"r\") as f:\n",
    "        lines = [line for line in f if line.strip()]\n",
    "    nlines = len(lines)\n",
    "    OBJ_Weights = <double **>chk_malloc(nf * sizeof(void*))\n",
    "    for i in range(nf):\n",
    "        OBJ_Weights[i] = <double *>chk_malloc(nlines * sizeof(double))\n",
    "    for i, line in enumerate(lines):\n",
    "        vals = line.strip().split()\n",
    "        for j in range(nf):\n",
    "            OBJ_Weights[j][i] = float(vals[j])\n",
    "    nombreLIGNE = nlines - 1\n",
    "    OBJ_Weights_lines = nlines\n",
    "\n",
    "cdef void dynamic_weight_allpop():\n",
    "    global vector_weight, OBJ_Weights, nombreLIGNE, nf, nextLn\n",
    "    cdef int i\n",
    "    if vector_weight == NULL:\n",
    "        vector_weight = <double *>chk_malloc(nf * sizeof(double))\n",
    "    for i in range(nf):\n",
    "        vector_weight[i] = OBJ_Weights[i][nextLn]\n",
    "    if nextLn == nombreLIGNE:\n",
    "        nextLn = 0\n",
    "    else:\n",
    "        nextLn += 1\n",
    "\n",
    "cdef void choose_weight():\n",
    "    dynamic_weight_allpop()\n",
    "\n",
    "cdef void random_init_ind(ind *x):\n",
    "    cdef int j, r, tmp\n",
    "    for j in range(ni):\n",
    "        x.d[j] = j\n",
    "    for j in range(ni):\n",
    "        r = irand(ni)\n",
    "        tmp = x.d[r]\n",
    "        x.d[r] = x.d[j]\n",
    "        x.d[j] = tmp\n",
    "\n",
    "cdef void evaluate(ind *x):\n",
    "    cdef int j, l, k, faisable\n",
    "    x.nombr = 0\n",
    "    x.nombr_nonpris = 0\n",
    "    for j in range(nf):\n",
    "        x.capa[j] = 0.0\n",
    "        x.f[j] = 0.0\n",
    "    for j in range(ni):\n",
    "        l = 0\n",
    "        faisable = 1\n",
    "        while l < nf and faisable == 1:\n",
    "            if x.capa[l] + weights[l][x.d[j]] > capacities[l]:\n",
    "                faisable = 0\n",
    "            l += 1\n",
    "        if faisable == 1:\n",
    "            for k in range(nf):\n",
    "                x.capa[k] += weights[k][x.d[j]]\n",
    "                x.f[k] += profits[k][x.d[j]]\n",
    "            x.Items[x.d[j]] = 1\n",
    "            x.nombr += 1\n",
    "        else:\n",
    "            x.Items[x.d[j]] = 0\n",
    "            x.nombr_nonpris += 1\n",
    "\n",
    "cdef void P_init_pop(pop *SP, pop *Sarchive, int alpha):\n",
    "    cdef int i, x, tmp, t\n",
    "    t = max(alpha, Sarchive.size)\n",
    "    cdef int* shuffle = <int *>chk_malloc(t * sizeof(int))\n",
    "    for i in range(t):\n",
    "        shuffle[i] = i\n",
    "    for i in range(t):\n",
    "        x = irand(alpha)\n",
    "        tmp = shuffle[i]\n",
    "        shuffle[i] = shuffle[x]\n",
    "        shuffle[x] = tmp\n",
    "    SP.size = alpha\n",
    "    if Sarchive.size > alpha:\n",
    "        for i in range(alpha):\n",
    "            SP.ind_array[i] = ind_copy(Sarchive.ind_array[shuffle[i]])\n",
    "    else:\n",
    "        for i in range(alpha):\n",
    "            if shuffle[i] < Sarchive.size:\n",
    "                SP.ind_array[i] = ind_copy(Sarchive.ind_array[shuffle[i]])\n",
    "            else:\n",
    "                SP.ind_array[i] = create_ind(nf)\n",
    "                random_init_ind(SP.ind_array[i])\n",
    "                evaluate(SP.ind_array[i])\n",
    "    free(shuffle)\n",
    "\n",
    "cdef int extractPtoArchive(pop *P, pop *archive):\n",
    "    cdef int i, j, dom, t, convergence_rate\n",
    "    t = archive.size + P.size\n",
    "    archiveAndP = create_pop(t, nf)\n",
    "    convergence_rate = 0\n",
    "    for i in range(archive.size):\n",
    "        archiveAndP.ind_array[i] = archive.ind_array[i]\n",
    "    for i in range(P.size):\n",
    "        archiveAndP.ind_array[i + archive.size] = ind_copy(P.ind_array[i])\n",
    "    archiveAndP.size = t\n",
    "    archive.size = 0\n",
    "    for i in range(t):\n",
    "        for j in range(t):\n",
    "            if i != j:\n",
    "                dom = non_dominated(archiveAndP.ind_array[i], archiveAndP.ind_array[j])\n",
    "                if dom == -1 or (dom == 0 and i > j):\n",
    "                    break\n",
    "        else:\n",
    "            archive.ind_array[archive.size] = ind_copy(archiveAndP.ind_array[i])\n",
    "            archive.size += 1\n",
    "            if i >= t - P.size:\n",
    "                convergence_rate += 1\n",
    "    complete_free_pop(archiveAndP)\n",
    "    return convergence_rate\n",
    "\n",
    "cdef double calcMaxbound(pop *SP, int size):\n",
    "    global max_bound\n",
    "    cdef int i, j\n",
    "    SP.size = size\n",
    "    cdef double max_b = SP.ind_array[0].v[0]\n",
    "    for i in range(SP.size):\n",
    "        for j in range(nf):\n",
    "            if max_b < SP.ind_array[i].v[j]:\n",
    "                max_b = SP.ind_array[i].v[j]\n",
    "    if max_b == 0.0:\n",
    "        max_b = 1e-8\n",
    "    max_bound = max_b\n",
    "    return max_b\n",
    "\n",
    "cdef void calcul_weight(pop *SP, int size):\n",
    "    cdef int i, j\n",
    "    for i in range(SP.size):\n",
    "        for j in range(nf):\n",
    "            SP.ind_array[i].v[j] = SP.ind_array[i].f[j] * vector_weight[j]\n",
    "\n",
    "cdef int compute_fitness_and_select(pop *SP, ind *x, int size):\n",
    "    cdef int i, worst\n",
    "    cdef double worst_fit, fit_tmp\n",
    "    SP.size = size\n",
    "    x.fitness = 0\n",
    "    compute_ind_fitness(x, SP)\n",
    "    worst_fit = x.fitness\n",
    "    worst = -1\n",
    "    for i in range(SP.size):\n",
    "        fit_tmp = update_fitness_return(SP.ind_array[i].fitness, calcAddEpsIndicator(x, SP.ind_array[i]))\n",
    "        if fit_tmp > worst_fit:\n",
    "            worst = i\n",
    "            worst_fit = fit_tmp\n",
    "    fit_tmp = x.fitness\n",
    "    if worst == -1:\n",
    "        return -1\n",
    "    else:\n",
    "        for i in range(SP.size):\n",
    "            delete_fitness(SP.ind_array[i], calcAddEpsIndicator(SP.ind_array[worst], SP.ind_array[i]))\n",
    "            update_fitness(SP.ind_array[i], calcAddEpsIndicator(x, SP.ind_array[i]))\n",
    "        delete_fitness(x, calcAddEpsIndicator(SP.ind_array[worst], x))\n",
    "        free_ind(SP.ind_array[worst])\n",
    "        SP.ind_array[worst] = ind_copy(x)\n",
    "        if fit_tmp - worst_fit > smallValue:\n",
    "            return worst\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "cdef np.ndarray get_archive_objs(pop *archive):\n",
    "    cdef int i, j\n",
    "    arr = np.zeros((archive.size, nf), dtype=np.float64)\n",
    "    for i in range(archive.size):\n",
    "        for j in range(nf):\n",
    "            arr[i, j] = archive.ind_array[i].f[j]\n",
    "    return arr\n",
    "\n",
    "cdef np.ndarray get_items(ind *x):\n",
    "    arr = np.zeros(ni, dtype=np.int32)\n",
    "    cdef int i\n",
    "    for i in range(ni):\n",
    "        arr[i] = x.Items[i]\n",
    "    return arr\n",
    "\n",
    "cdef tuple cy_mutation_move(np.ndarray[np.int32_t, ndim=1] items, int ni):\n",
    "    cdef int n_selected = 0, n_unselected = 0, i\n",
    "    for i in range(ni):\n",
    "        if items[i] == 1: n_selected += 1\n",
    "        else: n_unselected += 1\n",
    "    if n_selected == 0 or n_unselected == 0:\n",
    "        return (0, 0)\n",
    "    sel = [i for i in range(ni) if items[i] == 1]\n",
    "    unsel = [i for i in range(ni) if items[i] == 0]\n",
    "    remove_idx = sel[irand(n_selected)]\n",
    "    add_idx = unsel[irand(n_unselected)]\n",
    "    return remove_idx, add_idx\n",
    "\n",
    "cdef tuple cy_local_search_move(np.ndarray[np.int32_t, ndim=1] items, double[:, :] profits, int ni, int nf):\n",
    "    cdef int i\n",
    "    sel = [i for i in range(ni) if items[i] == 1]\n",
    "    unsel = [i for i in range(ni) if items[i] == 0]\n",
    "    if not sel or not unsel:\n",
    "        return (0, 0)\n",
    "    profs_selected = [sum([profits[f, idx] for f in range(nf)]) for idx in sel]\n",
    "    profs_unselected = [sum([profits[f, idx] for f in range(nf)]) for idx in unsel]\n",
    "    remove_idx = sel[np.argmin(profs_selected)]\n",
    "    add_idx = unsel[np.argmax(profs_unselected)]\n",
    "    return remove_idx, add_idx\n",
    "\n",
    "cdef tuple cy_global_search_move(np.ndarray[np.int32_t, ndim=1] items, double[:, :] profits, int ni, int nf):\n",
    "    cdef int i\n",
    "    sel = [i for i in range(ni) if items[i] == 1]\n",
    "    unsel = [i for i in range(ni) if items[i] == 0]\n",
    "    if not sel or not unsel:\n",
    "        return (0, 0)\n",
    "    profs_selected = np.array([sum([profits[f, idx] for f in range(nf)]) for idx in sel], dtype=np.float64) + 1e-9\n",
    "    profs_unselected = np.array([sum([profits[f, idx] for f in range(nf)]) for idx in unsel], dtype=np.float64) + 1e-9\n",
    "    remove_idx = sel[np.random.choice(len(sel), p=profs_selected/np.sum(profs_selected))]\n",
    "    add_idx = unsel[np.random.choice(len(unsel), p=profs_unselected/np.sum(profs_unselected))]\n",
    "    return remove_idx, add_idx\n",
    "\n",
    "def get_profits_np():\n",
    "    global profits, nf, ni\n",
    "    arr = np.zeros((nf, ni), dtype=np.float64)\n",
    "    for f in range(nf):\n",
    "        for i in range(ni):\n",
    "            arr[f, i] = profits[f][i]\n",
    "    return arr\n",
    "\n",
    "cdef void Indicator_local_search1(pop *SP, pop *Sarchive, int size):\n",
    "    cdef ind *x\n",
    "    cdef ind *y\n",
    "    cdef int i_idx, j_idx, r_idx, t_idx, k_idx, l_idx, v_idx, sol_idx, mino_idx, mp_idx, maxp_idx\n",
    "    cdef int consistant, pos_idx, stop_idx, convergence, ii_idx, tmp_pris, tmp_nonpris, taille, feasible, tv_idx, IM_idx\n",
    "    cdef int* remplace = <int *>chk_malloc(L * sizeof(int))\n",
    "    cdef np.ndarray[np.int32_t, ndim=1] items_mv = np.empty(ni, dtype=np.int32)\n",
    "    SP.size = size\n",
    "    extractPtoArchive(SP, Sarchive)\n",
    "    profits_np = get_profits_np()\n",
    "    while True:\n",
    "        convergence = 0\n",
    "        archive_objs = get_archive_objs(Sarchive) if Sarchive.size > 0 else None\n",
    "        loop_start_time = time.time()\n",
    "        for i_idx in range(SP.size):\n",
    "            if not SP.ind_array[i_idx].explored:\n",
    "                x = ind_copy(SP.ind_array[i_idx])\n",
    "                j_idx = 0\n",
    "                while j_idx < x.nombr:\n",
    "                    for l_idx in range(L):\n",
    "                        remplace[l_idx] = 0\n",
    "                    for ii_idx in range(ni):\n",
    "                        items_mv[ii_idx] = x.Items[ii_idx]\n",
    "                    \n",
    "                    move_types = [\"mutation\", \"local_search\", \"global_search\", \"follow\", \"diversity\"]\n",
    "                    mt_idx = irand(5)\n",
    "                    move_type = move_types[mt_idx]\n",
    "                    remove_idx = -1\n",
    "                    add_idx = -1\n",
    "                    agent_move_type = move_type\n",
    "                    agent_success = False\n",
    "                    agent_start_time = time.time()\n",
    "                    \n",
    "                    if move_type == \"mutation\":\n",
    "                        remove_idx, add_idx = cy_mutation_move(items_mv, ni)\n",
    "                    elif move_type == \"local_search\":\n",
    "                        remove_idx, add_idx = cy_local_search_move(items_mv, profits_np, ni, nf)\n",
    "                    elif move_type == \"global_search\":\n",
    "                        remove_idx, add_idx = cy_global_search_move(items_mv, profits_np, ni, nf)\n",
    "                    elif (move_type == \"diversity\" or move_type == \"follow\") and py_agent_manager is not None:\n",
    "                        agent_idx = i_idx % py_agent_manager.num_agents\n",
    "                        agent = py_agent_manager.agents[agent_idx]\n",
    "                        state = {\n",
    "                            \"Items\": [x.Items[ii_idx] for ii_idx in range(ni)],\n",
    "                            \"capa\": [x.capa[ii_idx] for ii_idx in range(nf)],\n",
    "                            \"f\": [x.f[ii_idx] for ii_idx in range(nf)],\n",
    "                        }\n",
    "                        context = {}\n",
    "                        if archive_objs is not None:\n",
    "                            context[\"archive_objs\"] = archive_objs\n",
    "                        try:\n",
    "                            obs = agent.observe(state)\n",
    "                            remove_idx, add_idx = agent.act(obs, context)\n",
    "                            if hasattr(agent, \"last_move_type\"):\n",
    "                                agent_move_type = agent.last_move_type\n",
    "                        except Exception as e:\n",
    "                            print(\"Agent error:\", e)\n",
    "                            remove_idx = -1\n",
    "                            add_idx = -1\n",
    "                            agent_move_type = \"error\"\n",
    "                    \n",
    "                    agent_end_time = time.time()\n",
    "                    if move_stats is not None:\n",
    "                        move_stats[\"total_agent_calls\"] += 1\n",
    "                        move_stats[\"total_time_agent\"] += (agent_end_time - agent_start_time)\n",
    "                        mt = agent_move_type if agent_move_type is not None else \"unknown\"\n",
    "                        if mt not in move_stats[\"move_type_counts\"]:\n",
    "                            move_stats[\"move_type_counts\"][mt] = 0\n",
    "                        move_stats[\"move_type_counts\"][mt] += 1\n",
    "                    \n",
    "                    if remove_idx < 0 or remove_idx >= ni or x.Items[remove_idx] != 1:\n",
    "                        while True:\n",
    "                            mino_idx = irand(ni)\n",
    "                            if x.Items[mino_idx] == 1:\n",
    "                                break\n",
    "                        remove_idx = mino_idx\n",
    "                    if add_idx < 0 or add_idx >= ni or x.Items[add_idx] != 0 or add_idx == remove_idx:\n",
    "                        while True:\n",
    "                            maxp_idx = irand(ni)\n",
    "                            if x.Items[maxp_idx] == 0 and maxp_idx != remove_idx:\n",
    "                                break\n",
    "                        add_idx = maxp_idx\n",
    "                    \n",
    "                    x.Items[remove_idx] = 0\n",
    "                    x.nombr -= 1\n",
    "                    x.nombr_nonpris += 1\n",
    "                    for r_idx in range(nf):\n",
    "                        x.capa[r_idx] -= weights[r_idx][remove_idx]\n",
    "                        x.f[r_idx] -= profits[r_idx][remove_idx]\n",
    "                    \n",
    "                    IM_idx = 0\n",
    "                    taille = 0\n",
    "                    while IM_idx < L:\n",
    "                        item_to_add = add_idx\n",
    "                        if item_to_add < 0 or item_to_add >= ni or x.Items[item_to_add] != 0 or item_to_add == remove_idx:\n",
    "                            while True:\n",
    "                                item_to_add = irand(ni)\n",
    "                                if x.Items[item_to_add] == 0 and item_to_add != remove_idx:\n",
    "                                    break\n",
    "                        consistant = 1\n",
    "                        r_idx = 0\n",
    "                        while r_idx < nf and consistant == 1:\n",
    "                            if x.capa[r_idx] + weights[r_idx][item_to_add] > capacities[r_idx]:\n",
    "                                consistant = 0\n",
    "                            r_idx += 1\n",
    "                        if consistant == 1:\n",
    "                            feasible = 1\n",
    "                            r_idx = 0\n",
    "                            while r_idx < taille and feasible:\n",
    "                                if item_to_add == remplace[r_idx]:\n",
    "                                    feasible = 0\n",
    "                                r_idx += 1\n",
    "                            if feasible == 1:\n",
    "                                remplace[taille] = item_to_add\n",
    "                                taille += 1\n",
    "                                x.Items[item_to_add] = 1\n",
    "                                x.nombr_nonpris -= 1\n",
    "                                x.nombr += 1\n",
    "                                for r_idx in range(nf):\n",
    "                                    x.capa[r_idx] += weights[r_idx][item_to_add]\n",
    "                                    x.f[r_idx] += profits[r_idx][item_to_add]\n",
    "                        IM_idx += 1\n",
    "                    \n",
    "                    for tv_idx in range(nf):\n",
    "                        x.v[tv_idx] = x.f[tv_idx] * vector_weight[tv_idx]\n",
    "                    \n",
    "                    max_bound = calcMaxbound(SP, SP.size)\n",
    "                    sol_idx = compute_fitness_and_select(SP, x, SP.size)\n",
    "                    agent_success = (sol_idx != -1)\n",
    "                    \n",
    "                    if py_agent_manager is not None and (move_type == \"diversity\" or move_type == \"follow\"):\n",
    "                        try:\n",
    "                            agent.report_move_result(agent_move_type, agent_success)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    \n",
    "                    if py_agent_manager is not None:\n",
    "                        agent_idx = i_idx % py_agent_manager.num_agents\n",
    "                        fitness = np.sum([x.f[j_idx] for j_idx in range(nf)])\n",
    "                        py_agent_manager.report_agent_performance(agent_idx, fitness)\n",
    "                    \n",
    "                    if sol_idx != -1:\n",
    "                        j_idx = x.nombr + 1\n",
    "                        if sol_idx > i_idx and i_idx + 1 < SP.size:\n",
    "                            y = SP.ind_array[i_idx + 1]\n",
    "                            SP.ind_array[i_idx + 1] = SP.ind_array[sol_idx]\n",
    "                            SP.ind_array[sol_idx] = y\n",
    "                            i_idx += 1\n",
    "                        break\n",
    "                    elif sol_idx == -1:\n",
    "                        x.Items[remove_idx] = 1\n",
    "                        x.nombr_nonpris -= 1\n",
    "                        x.nombr += 1\n",
    "                        for r_idx in range(nf):\n",
    "                            x.capa[r_idx] += weights[r_idx][remove_idx]\n",
    "                            x.f[r_idx] += profits[r_idx][remove_idx]\n",
    "                        if taille >= 1:\n",
    "                            for r_idx in range(taille):\n",
    "                                x.Items[remplace[r_idx]] = 0\n",
    "                                x.nombr -= 1\n",
    "                                x.nombr_nonpris += 1\n",
    "                                for t_idx in range(nf):\n",
    "                                    x.capa[t_idx] -= weights[t_idx][remplace[r_idx]]\n",
    "                                    x.f[t_idx] -= profits[t_idx][remplace[r_idx]]\n",
    "                                    x.v[t_idx] = x.f[t_idx] * vector_weight[t_idx]\n",
    "                    j_idx += 1\n",
    "                tmp_pris = x.nombr\n",
    "                tmp_nonpris = x.nombr_nonpris\n",
    "                free_ind(x)\n",
    "                if j_idx == tmp_pris:\n",
    "                    SP.ind_array[i_idx].explored = 1\n",
    "        loop_end_time = time.time()\n",
    "        if move_stats is not None:\n",
    "            move_stats[\"total_time_loop\"] += (loop_end_time - loop_start_time)\n",
    "        convergence = extractPtoArchive(SP, Sarchive)\n",
    "        if not convergence:\n",
    "            break\n",
    "    free(remplace)\n",
    "\n",
    "def run_moacp(instance_file, weights_file, nbitems, num_objectives, output_file):\n",
    "    global nf, ni, NBITEMS, alpha, paretoIni, L, nombreLIGNE, nextLn, inv, vector_weight\n",
    "    global capacities, weights, profits, OBJ_Weights\n",
    "    \n",
    "    alpha = 10\n",
    "    paretoIni = 28000\n",
    "    NBL = 25\n",
    "    NRUNS = 3\n",
    "    \n",
    "    reset_move_stats()\n",
    "    \n",
    "    for run in range(1, NRUNS+1):\n",
    "        NBITEMS = nbitems\n",
    "        ni = nbitems\n",
    "        nf = num_objectives\n",
    "        print(f\"RUN {run}/{NRUNS} -- {instance_file.decode()} nbitems={ni} nf={nf} => {output_file}\")\n",
    "        nombreLIGNE = 0\n",
    "        nextLn = 0\n",
    "        inv = 0\n",
    "        seed(run)\n",
    "        loadMOKP(instance_file)\n",
    "        read_weights_file(weights_file)\n",
    "        vector_weight = <double *>chk_malloc(nf * sizeof(double))\n",
    "        P = create_pop(paretoIni, nf)\n",
    "        it = 0\n",
    "        while it < NBL:\n",
    "            solutions = create_pop(alpha, nf)\n",
    "            archive = create_pop(paretoIni, nf)\n",
    "            choose_weight()\n",
    "            P_init_pop(solutions, P, alpha)\n",
    "            extractPtoArchive(solutions, P)\n",
    "            calcul_weight(solutions, alpha)\n",
    "            calcMaxbound(solutions, alpha)\n",
    "            compute_all_fitness(solutions)\n",
    "            Indicator_local_search1(solutions, archive, alpha)\n",
    "            extractPtoArchive(archive, P)\n",
    "            \n",
    "            if py_agent_manager is not None and hasattr(py_agent_manager, \"gses_agent_level\") and it % 10 == 0:\n",
    "                py_agent_manager.gses_agent_level()\n",
    "                if it % 20 == 0 and hasattr(py_agent_manager, \"evolve_with_llm\"):\n",
    "                    py_agent_manager.evolve_with_llm()\n",
    "            \n",
    "            it += 1\n",
    "            complete_free_pop(solutions)\n",
    "            complete_free_pop(archive)\n",
    "        \n",
    "        with open(output_file, \"a\") as fpareto:\n",
    "            fpareto.write(\"\\n\")\n",
    "            for i in range(P.size):\n",
    "                for j in range(nf):\n",
    "                    fpareto.write(f\"{P.ind_array[i].f[j]:.6f} \")\n",
    "                fpareto.write(\"\\n\")\n",
    "        \n",
    "        complete_free_pop(P)\n",
    "        cleanup_globals()\n",
    "        print_move_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296aa16d-fa83-419a-ae39-0af4cb1d52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-generating functions...\n"
     ]
    }
   ],
   "source": [
    "# --- Parameters and File Names ---\n",
    "nbitems = 250\n",
    "num_objectives = 2\n",
    "instance_file = b\"250.2.txt\"\n",
    "weights_file = b\"Weights_2obj_FQ200.txt\"\n",
    "output_file = \"kss5_llm_enhanced.txt\"\n",
    "random_seed = 42\n",
    "\n",
    "# 1. Load your instance as usual\n",
    "profits = load_profits_from_file(\"250.2.txt\", num_objectives, nbitems)\n",
    "weights = load_weights_from_file(\"250.2.txt\", num_objectives, nbitems)\n",
    "capacities = load_capacities_from_file(\"250.2.txt\", num_objectives, nbitems)\n",
    "\n",
    "# 2. Create LLM function generator\n",
    "llm_generator = LLMFunctionGenerator()\n",
    "\n",
    "# 3. Pre-generate functions before optimization starts\n",
    "print(\"Pre-generating functions...\")\n",
    "llm_generator.pre_generate_functions()\n",
    "\n",
    "# 4. Create the enhanced modular MHRE agent population\n",
    "# Use a smaller number of agents for faster execution\n",
    "agent_manager = EnhancedAgentPopulationManager(\n",
    "    num_agents=5,  # Reduced from 10 to 5\n",
    "    num_items=nbitems,\n",
    "    num_objectives=num_objectives,\n",
    "    profits=profits,\n",
    "    weights=weights,\n",
    "    capacities=capacities,\n",
    "    llm_generator=llm_generator\n",
    ")\n",
    "\n",
    "# 5. Register agent manager with cython\n",
    "set_agent_manager(agent_manager)\n",
    "\n",
    "# 6. Run the optimizer with reduced iterations for testing\n",
    "print(\"Starting optimization...\")\n",
    "run_moacp(instance_file, weights_file, nbitems, num_objectives, output_file)\n",
    "print(\"Optimization completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2c1b8-8f5f-45e5-b264-4b1bdbfea67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_pareto_front(filename):\n",
    "    points = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                points.append([float(x) for x in line.split()])\n",
    "    return np.array(points)\n",
    "\n",
    "def is_dominated(point, others):\n",
    "    \"\"\"Returns True if point is dominated by any row in others\"\"\"\n",
    "    return np.any(np.all(others >= point, axis=1) & np.any(others > point, axis=1))\n",
    "\n",
    "def get_pareto_front(points):\n",
    "    mask = np.ones(len(points), dtype=bool)\n",
    "    for i, p in enumerate(points):\n",
    "        others = np.delete(points, i, axis=0)\n",
    "        if is_dominated(p, others):\n",
    "            mask[i] = False\n",
    "    return points[mask]\n",
    "\n",
    "# Load and merge all runs' points for each result file\n",
    "ref_points = load_pareto_front(\"2502_Resulats.txt\")\n",
    "new_points = load_pareto_front(\"kss5_llm_enhanced.txt\")\n",
    "\n",
    "# Get the true Pareto front for each\n",
    "ref_pareto = get_pareto_front(ref_points)\n",
    "new_pareto = get_pareto_front(new_points)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(ref_pareto[:,0], ref_pareto[:,1], label=\"Reference True Pareto\", alpha=0.7, color='blue')\n",
    "plt.scatter(new_pareto[:,0], new_pareto[:,1], label=\"LLM-Enhanced True Pareto\", alpha=0.7, color='red')\n",
    "plt.xlabel(\"Objective 1\")\n",
    "plt.ylabel(\"Objective 2\")\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Pareto Fronts: Reference vs LLM-Enhanced\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate hypervolume improvement\n",
    "def hypervolume(points, reference_point):\n",
    "    \"\"\"Calculate hypervolume indicator for a set of points.\"\"\"\n",
    "    sorted_points = sorted(points, key=lambda x: x[0])\n",
    "    volume = 0.0\n",
    "    prev_x = reference_point[0]\n",
    "    for point in sorted_points:\n",
    "        width = prev_x - point[0]\n",
    "        height = reference_point[1] - point[1]\n",
    "        volume += width * height\n",
    "        prev_x = point[0]\n",
    "    return volume\n",
    "\n",
    "# Find reference point (max of each objective + 10%)\n",
    "ref_point = np.max(np.vstack([ref_pareto, new_pareto]), axis=0) * 1.1\n",
    "\n",
    "# Calculate hypervolumes\n",
    "ref_hv = hypervolume(ref_pareto, ref_point)\n",
    "new_hv = hypervolume(new_pareto, ref_point)\n",
    "\n",
    "print(f\"Reference Pareto Front Hypervolume: {ref_hv:.2f}\")\n",
    "print(f\"LLM-Enhanced Pareto Front Hypervolume: {new_hv:.2f}\")\n",
    "print(f\"Improvement: {(new_hv - ref_hv) / ref_hv * 100:.2f}%\")\n",
    "\n",
    "# Plot agent performance over generations\n",
    "if hasattr(agent_manager, 'performance_history') and agent_manager.performance_history:\n",
    "    generations = [p['generation'] for p in agent_manager.performance_history]\n",
    "    best_fitness = [p['best_fitness'] for p in agent_manager.performance_history]\n",
    "    avg_fitness = [p['avg_fitness'] for p in agent_manager.performance_history]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(generations, best_fitness, label='Best Fitness', marker='o')\n",
    "    plt.plot(generations, avg_fitness, label='Average Fitness', marker='s')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.title('Agent Population Performance Over Generations')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c70e79-b31d-49de-8a75-bd4aea2dec42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "281399af-893f-43a3-a040-96d7506df436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in a:\\conda\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in a:\\conda\\lib\\site-packages (from scikit-learn) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in a:\\conda\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in a:\\conda\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in a:\\conda\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (a:\\conda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (a:\\conda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (a:\\conda\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9178fb-7429-4e1f-a57c-5f6814ea82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A:\\conda\\envs\\ibmols\\python.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe61c8cf-8b57-4318-aba1-82866693faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\\conda\\envs\\ibmols\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f46c2ef-00d8-483f-a463-cbdce13e5f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\\conda\\envs\\ibmols\\lib\\site-packages\\sklearn\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c0d7d6-191f-4d2d-ab33-6b37f76e6486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4 1.13.1 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy, scipy, sklearn\n",
    "print(numpy.__version__, scipy.__version__, sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac25d38-4d43-48e0-99d9-5d1fbf7b7764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2821c1-c43c-4d1b-aa03-99a10dbb814f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005bb47b-b1ae-4aab-9c1c-eccd0a211bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3', 'created_at': '2025-09-06T17:51:18.9589415Z', 'response': \"A nice simple one!\\n\\nThe function `f` is defined as:\\n```\\ndef f(): return 1\\n```\\nThis is a function that takes no arguments and returns the value `1`.\\n\\nYou can call this function like any other:\\n```\\nresult = f()\\nprint(result)  # Output: 1\\n```\\nNote that there's no parameter list (`()`), which means the function doesn't take any arguments. The `return` statement specifies what value is returned when the function is called. In this case, it's always `1`.\", 'done': True, 'done_reason': 'stop', 'context': [128006, 882, 128007, 271, 755, 282, 4658, 471, 220, 16, 128009, 128006, 78191, 128007, 271, 32, 6555, 4382, 832, 2268, 791, 734, 1595, 69, 63, 374, 4613, 439, 512, 14196, 4077, 755, 282, 4658, 471, 220, 16, 198, 14196, 4077, 2028, 374, 264, 734, 430, 5097, 912, 6105, 323, 4780, 279, 907, 1595, 16, 63438, 2675, 649, 1650, 420, 734, 1093, 904, 1023, 512, 14196, 4077, 1407, 284, 282, 746, 1374, 4556, 8, 220, 674, 9442, 25, 220, 16, 198, 14196, 4077, 9290, 430, 1070, 596, 912, 5852, 1160, 29754, 55358, 705, 902, 3445, 279, 734, 3250, 956, 1935, 904, 6105, 13, 578, 1595, 693, 63, 5224, 30202, 1148, 907, 374, 6052, 994, 279, 734, 374, 2663, 13, 763, 420, 1162, 11, 433, 596, 2744, 1595, 16, 29687], 'total_duration': 68201153400, 'load_duration': 37253043700, 'prompt_eval_count': 16, 'prompt_eval_duration': 2217840700, 'eval_count': 114, 'eval_duration': 28587394000}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "resp = requests.post(\"http://localhost:11434/api/generate\", json={\"model\": \"llama3\", \"prompt\": \"def f(): return 1\", \"stream\": False})\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815102f6-ec1f-434b-abc7-33093dadbc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ibmols)",
   "language": "python",
   "name": "ibmols"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
